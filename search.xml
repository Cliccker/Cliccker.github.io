<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>结构化标准的教程</title>
      <link href="/2020/08/03/jie_gou_hua_biao_zhun/"/>
      <url>/2020/08/03/jie_gou_hua_biao_zhun/</url>
      
        <content type="html"><![CDATA[<h2 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h2><ul><li>福昕PDF阅读器</li><li>office2016以上版本或wps</li><li>Typora Markdown</li></ul><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ol><li><p>使用word打开对应PDF文档，等待文档转换成可以编辑的格式。</p></li><li><p>打开识别成功的文件，清除所有的格式，将所用空格替换掉，全部<code>．</code>和<code>·</code>替换成<code>.</code>，全部<code>一</code>替换成<code>-</code></p></li><li><p>标题的处理</p><p>Markdown中的语法，#+“空格”+“文字” 就能设置标题。也可以在标题行按ctrl+“级数”设置标题等级。具体格式参考</p><p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200803165011.png" alt="标题示例"></p></li><li><p>段落的处理</p><p>检查是否有错误和纰漏，确认无误之后将对应标题下的文字复制粘贴到Typora里。</p><p>粘贴之后用代码模式检查是否存在图片，如果存在就删除。</p></li><li><p>公式、表和图的处理</p><p>段落中引用公式参考</p><blockquote><p>计入强度计算的复合材料的折算厚度可按式（3-1a）计算:</p></blockquote><p>公式本身用￥+“公式编号”+￥表示，单独占一行，示例</p><blockquote><p>￥式（3-1a）￥</p></blockquote><p>句中的公式和元素用￥￥代替，示例</p><blockquote><p>本标准所用材料的设计应力强度值￥￥</p></blockquote><p>段落中引用表格，示例</p><blockquote><p>在设计容器各部分时，必须按表3-1考虑压力、温度及静压头之间的相互关系。</p></blockquote><p>表格用如下格式表示</p><blockquote><p>￥表3-1 ￥压力与温度之间的关系</p></blockquote><p>图片的处理方式和表格相同</p></li><li><p>在处理名词术语时，要尽可能地分级，例如</p></li></ol><p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200805142052.png" alt="示例"></p>]]></content>
      
      
      <categories>
          
          <category> 技巧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PDF </tag>
            
            <tag> word </tag>
            
            <tag> 结构化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人们怕人工智能获得意识到底是怕哪个方面？</title>
      <link href="/2020/07/29/wei_shi_me_ren_lei_hui_hai_pa_ren_gong_zhi_neng/"/>
      <url>/2020/07/29/wei_shi_me_ren_lei_hui_hai_pa_ren_gong_zhi_neng/</url>
      
        <content type="html"><![CDATA[<p>我一直认为人类的许多表现，都是原始本能在现代社会中的映射。编造个小故事：</p><p>在这片原始的大陆上，生活着许多不同的原始部族。<code>咚塔塔人</code>也是其中一员，或许是因为脑容量大一丢丢吧，咚塔塔人首先悟出了三条生存的准则：</p><ol><li>猎物的肉-火烤-吃；</li><li>猎物的皮毛-剥下来-穿在身上-不冷 ；</li><li>猎物的腿骨-敲碎-敌人的脑袋。</li></ol><p>很快他们悟到了第四条准则：</p><ol start="4"><li>笨蛋脑袋可以不敲碎，拿来生孩子当苦力</li></ol><p>接着是第五条：</p><ol start="5"><li>笨蛋脑袋不好用，教会前三条就好用了</li></ol><p>然后是笨蛋脑袋中学会了前三条，并悟出了第六条：</p><ol start="6"><li>咚塔塔人能做到的，我们也能！敲碎他们的脑袋！</li></ol><p>我想表达的是，令人们感到恐惧的不是人工智能产生意识——我们可以利用这些意识实现更多的价值——而是人工智能<strong>越来越接近</strong>人类。从某种意义上来说，人们就是在害怕自己。</p>]]></content>
      
      
      <categories>
          
          <category> 想法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 科幻 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>向量相似度计算方法</title>
      <link href="/2020/07/27/xiang_liang_xiang_si_du_ji_suan_fang_fa/"/>
      <url>/2020/07/27/xiang_liang_xiang_si_du_ji_suan_fang_fa/</url>
      
        <content type="html"><![CDATA[<p>最近在做的嵌入模型比较，需要用到比较向量相似度，在知乎上看到了<a href="https://zhuanlan.zhihu.com/p/33164335" target="_blank" rel="noopener">一篇文章</a>，简单搬运过来做一些笔记和代码实践。首先列举一些向量相似度计算的方法：</p><ol><li>欧式距离（Euclidean Distance）</li><li>余弦相似度（Cosine Similarity）</li><li>皮尔逊相关系数（Pearson）</li><li>修正余弦相似度（Adjusted Cosine）</li><li>汉明距离（Hamming Distance）</li><li>曼哈顿距离（Manhattan Distance）</li><li>切比雪夫距离（Chebyshev Distance）</li></ol><h2 id="欧式距离（Euclidean-Distance）"><a href="#欧式距离（Euclidean-Distance）" class="headerlink" title="欧式距离（Euclidean Distance）"></a>欧式距离（Euclidean Distance）</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>欧氏距离比较容易理解，就是两点之间的直线距离，二以此类推空间中的两点$a(x_1,y_1)和b(x_2,y_2)$的欧式距离可以表示为：<br>$$<br>d=\sqrt{(x_1-x_2)^{2}+(y_1-y_2)^{2}}<br>$$<br>多维空间中的两点之间欧式距离可以表示为：<br>$$<br>d=\sqrt{(x_1-x_2)^{2}+(y_1-y_2)^{2}+(z_1-z_2)^{2}+···}<br>$$</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>python简单实现：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">EuclideanDistance</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    d <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> a<span class="token punctuation">,</span> b <span class="token keyword">in</span> zip<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># zip将两个列表打包为元组的列表</span>        d <span class="token operator">+=</span> <span class="token punctuation">(</span>a <span class="token operator">-</span> b<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>    <span class="token keyword">return</span> d <span class="token operator">**</span> <span class="token number">0.5</span></code></pre><p>使用numpy计算：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">EuclideanDistance_np</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># np.linalg.norm 用于范数计算，默认是二范数，相当于平方和开根号</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>经测试，对于同样的两组向量，两个函数的结果相同。</p><h2 id="余弦相似度（Cosine-Similarity）"><a href="#余弦相似度（Cosine-Similarity）" class="headerlink" title="余弦相似度（Cosine Similarity）"></a>余弦相似度（Cosine Similarity）</h2><h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><blockquote><p>首先，样本数据的夹角余弦并不是真正几何意义上的夹角余弦，只不过是借了它的名字，实际是借用了它的概念变成了是代数意义上的“夹角余弦”，用来衡量样本向量间的差异。</p></blockquote><p>夹角越小，余弦值越接近1，反之越接近-1。假设有两个向量$\vec x_1,\vec x_2$:<br>$$<br>\cos (\theta)=\frac{\sum_{k=1}^{n} x_{1 k} x_{2 k}}{\sqrt{\sum_{k=1}^{n} x_{1 k}^{2}} \sqrt{\sum_{k=1}^{n} x_{2 k}^{2}}}<br>$$</p><h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><p>用python实现该公式：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">Cosine</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    sum_xy <span class="token operator">=</span> <span class="token number">0</span>    num_x <span class="token operator">=</span> <span class="token number">0</span>    num_y <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> a<span class="token punctuation">,</span> b <span class="token keyword">in</span> zip<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        sum_xy <span class="token operator">+=</span> a <span class="token operator">*</span> b        num_x <span class="token operator">+=</span> a <span class="token operator">**</span> <span class="token number">2</span>        num_y <span class="token operator">+=</span> b <span class="token operator">**</span> <span class="token number">2</span>    <span class="token keyword">if</span> num_x <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">or</span> num_y <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 判断分母是否为零</span>        <span class="token keyword">return</span> None    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> sum_xy <span class="token operator">/</span> <span class="token punctuation">(</span>num_y <span class="token operator">*</span> num_x<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">0.5</span>V_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>V_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>V_z <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>Cosine<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 0.9956602816447043</span><span class="token keyword">print</span><span class="token punctuation">(</span>Cosine<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 1.0</span></code></pre><p>用numpy简化计算过程，用相同的向量测试：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">Cosine_np</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">)</span>      b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    d <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>b<span class="token punctuation">)</span>     <span class="token keyword">return</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span> <span class="token operator">/</span> d V_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>V_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>V_z <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>Cosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.9956602816447043</span><span class="token keyword">print</span><span class="token punctuation">(</span>Cosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 1.0000000000000002</span></code></pre><h2 id="欧式距离和余弦相似度的差异"><a href="#欧式距离和余弦相似度的差异" class="headerlink" title="欧式距离和余弦相似度的差异"></a>欧式距离和余弦相似度的差异</h2><p>来看输出结果的对比</p><pre class=" language-python"><code class="language-python">V_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>V_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>V_z <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>Cosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.9956602816447043</span><span class="token keyword">print</span><span class="token punctuation">(</span>Cosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 1.0000000000000002</span><span class="token keyword">print</span><span class="token punctuation">(</span>EuclideanDistance_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 1.7320508075688772</span><span class="token keyword">print</span><span class="token punctuation">(</span>EuclideanDistance_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 15.362291495737216</span></code></pre><p>从中可以看出</p><ul><li>$\vec x,\vec z$同向，他们的余弦距离为1，说明这两个向量<strong>方向一致</strong>，但是两者的欧式距离相差甚远，说明两者<strong>数值相差</strong>较大。</li><li>余弦相似度用来衡量两个向量之间的<strong>变化趋势</strong>，而欧式距离可以比较两个向量的<strong>数值差异</strong></li></ul><h2 id="皮尔逊相关系数（Pearson-Correlation-Coefficient）"><a href="#皮尔逊相关系数（Pearson-Correlation-Coefficient）" class="headerlink" title="皮尔逊相关系数（Pearson Correlation Coefficient）"></a>皮尔逊相关系数（Pearson Correlation Coefficient）</h2><h3 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h3><p>其公式如下：<br>$$<br>\operatorname{sim}\left(x_{1}, x_{2}\right)=\frac{\sum_{k=1}^{n}\left(x_{1 k}-\overline{x_{1}}\right)\left(x_{2 k}-\overline{x_{2}}\right)}{\sqrt{\sum_{k=1}^{n}\left(x_{1 k}-\overline{x_{1}}\right)^{2}} \sqrt{\sum_{k=1}^{n}\left(x_{2 k}-\overline{x_{2}}\right)^{2}}}<br>$$<br>$\overline x$表示均值</p><p>余弦相似度会受到向量的平移影响，为了实现平移不变性，在余弦相似度的基础上，每个向量减去这个向量均值组成的向量，也就是皮尔逊相关系数。</p><h3 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h3><p>python</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">Pearson</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>    sum_xy <span class="token operator">=</span> <span class="token number">0</span>    num_x <span class="token operator">=</span> <span class="token number">0</span>    num_y <span class="token operator">=</span> <span class="token number">0</span>    avr_x <span class="token operator">=</span> sum<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> len<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 求平均值</span>    avr_y <span class="token operator">=</span> sum<span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token operator">/</span> len<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    <span class="token keyword">for</span> a<span class="token punctuation">,</span> b <span class="token keyword">in</span> zip<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        sum_xy <span class="token operator">+=</span> <span class="token punctuation">(</span>a<span class="token operator">-</span>avr_x<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>b<span class="token operator">-</span>avr_y<span class="token punctuation">)</span>        num_x <span class="token operator">+=</span> <span class="token punctuation">(</span>a<span class="token operator">-</span>avr_x<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>        num_y <span class="token operator">+=</span> <span class="token punctuation">(</span>b<span class="token operator">-</span>avr_y<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>    <span class="token keyword">if</span> num_x <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">or</span> num_y <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 判断分母是否为零</span>        <span class="token keyword">return</span> None    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> sum_xy <span class="token operator">/</span> <span class="token punctuation">(</span>num_y <span class="token operator">*</span> num_x<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">0.5</span><span class="token comment" spellcheck="true">#0.9831290611762872</span><span class="token comment" spellcheck="true">#1.0</span></code></pre><p>引入numpy：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">Pearson_np</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># .corrcoef()是numpy中内置的计算皮尔逊相关系数的方法，同时需要进行归一化处理</span>    <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>corrcoef<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> rowvar<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200727192841.png" alt="关于.corrcoef()返回的值" style="zoom:67%;" /><p>当然也可以不使用该方法计算相似度，这里不多解释。</p><h2 id="余弦相似度于皮尔逊相关系数的比较"><a href="#余弦相似度于皮尔逊相关系数的比较" class="headerlink" title="余弦相似度于皮尔逊相关系数的比较"></a>余弦相似度于皮尔逊相关系数的比较</h2><pre class=" language-python"><code class="language-python">V_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>V_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>V_z <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>Cosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 1.0</span><span class="token keyword">print</span><span class="token punctuation">(</span>Cosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.9450766454656805</span><span class="token keyword">print</span><span class="token punctuation">(</span>Pearson_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 1.0</span><span class="token keyword">print</span><span class="token punctuation">(</span>Pearson_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.819092959946616</span></code></pre><p>从这个结果不容易理解皮尔逊相似系数。关于如何解释Pearson，我觉得<a href="https://www.zhihu.com/question/19734616/answer/174098489" target="_blank" rel="noopener">这个回答</a>写的比较好</p><p>他解释了为什么要<strong>中心化</strong></p><blockquote><p>中心化的意思是说, 对每个向量, 我先计算所有元素的平均值avg, 然后向量中每个维度的值都减去这个avg, 得到的这个向量叫做被中心化的向量. 机器学习, 数据挖掘要计算向量余弦相似度的时候, 由于向量经常在某个维度上有数据的缺失, 预处理阶段都要对所有维度的数值进行中心化处理.</p></blockquote><h2 id="修正余弦相似度（Adjusted-Cosine-Similarity）"><a href="#修正余弦相似度（Adjusted-Cosine-Similarity）" class="headerlink" title="修正余弦相似度（Adjusted Cosine Similarity）"></a>修正余弦相似度（Adjusted Cosine Similarity）</h2><h3 id="定义-3"><a href="#定义-3" class="headerlink" title="定义"></a>定义</h3><p>正如前文所说，余弦相似度对数值并不敏感，这种不敏感会使数值出现误差，因此我们要对其进行修正。</p><p>🌰：假设A用户为两部电影打分（1，2）B用户打分（9，10），这两个分数的余弦相似度是0.96，但是很显然，A并没有B那么喜欢第二部电影，这就产生了误差。</p><p>如何避免这种误差？答案是再引入去中心化的方法。其公式可以写成：<br>$$<br>\operatorname{adjcos<br>}\left(x_{1}, x_{2}\right)=\frac{\sum_{k=1}^{n}\left(x_{1 k}-\overline{x_{11}+x_{21}}\right)\left(x_{2 k}-\overline{x_{21}+x_{11}}\right)}{\sqrt{\sum_{k=1}^{n}\left(x_{1 k}-\overline{x_{11}+x_{21}}\right)^{2}} \sqrt{\sum_{k=1}^{n}\left(x_{2 k}-\overline{x_{21}+x_{11}}\right)^{2}}}<br>$$<br>仔细观察，他和公式（4）差别在哪里？每一项都减去了向量中第一项的平均值。</p><h3 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h3><p>尝试用python实现：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">AdjCosine</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    sum_xy <span class="token operator">=</span> <span class="token number">0</span>    num_x <span class="token operator">=</span> <span class="token number">0</span>    num_y <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> a<span class="token punctuation">,</span> b <span class="token keyword">in</span> zip<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        avr <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>        sum_xy <span class="token operator">+=</span> <span class="token punctuation">(</span>a <span class="token operator">-</span> avr<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>b <span class="token operator">-</span> avr<span class="token punctuation">)</span>        num_x <span class="token operator">+=</span> <span class="token punctuation">(</span>a <span class="token operator">-</span> avr<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>        num_y <span class="token operator">+=</span> <span class="token punctuation">(</span>b <span class="token operator">-</span> avr<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>    <span class="token keyword">if</span> num_x <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">or</span> num_y <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 判断分母是否为零</span>        <span class="token keyword">return</span> None    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>sum_xy <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>num_y <span class="token operator">*</span> num_x<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>使用numpy简化：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">AdjCosine_np</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    avr <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>    d <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a<span class="token operator">-</span>avr<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>b<span class="token operator">-</span>avr<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a<span class="token operator">-</span>avr<span class="token punctuation">,</span> b<span class="token operator">-</span>avr<span class="token punctuation">)</span> <span class="token operator">/</span> d<span class="token punctuation">)</span></code></pre><p>于余弦相似度进行对比：</p><pre class=" language-python"><code class="language-python">V_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>V_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span>V_z <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>AdjCosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.951797128930044</span><span class="token keyword">print</span><span class="token punctuation">(</span>AdjCosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.6889822365046137</span><span class="token keyword">print</span><span class="token punctuation">(</span>Cosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 1.0</span><span class="token keyword">print</span><span class="token punctuation">(</span>Cosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.9913538149119954</span></code></pre><p>可以看到两者的差别还是挺大的，说明数值的确产生了比较大的影响。</p><p>❓：思考一下，如果向量中的第0个元素相同，要怎么办呢？尝试一下：</p><pre class=" language-python"><code class="language-python">V_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>V_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>AdjCosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.9985272427507907</span></code></pre><p>果然，结果显示两个向量非常相似。要解决这个问题，我们可以参考Pearson的处理方法，用平均数构造修正函数。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">AdjCosine_np_2</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    avr <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>np<span class="token punctuation">.</span>append<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 合并矩阵并求矩阵的平均值</span>    d <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a <span class="token operator">-</span> avr<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>b <span class="token operator">-</span> avr<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a <span class="token operator">-</span> avr<span class="token punctuation">,</span> b <span class="token operator">-</span> avr<span class="token punctuation">)</span> <span class="token operator">/</span> d<span class="token punctuation">)</span>V_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>V_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span>V_z <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>AdjCosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.9985272427507907</span><span class="token keyword">print</span><span class="token punctuation">(</span>AdjCosine_np_2<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.6879115070007071</span><span class="token keyword">print</span><span class="token punctuation">(</span>AdjCosine_np<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.951797128930044</span><span class="token keyword">print</span><span class="token punctuation">(</span>AdjCosine_np_2<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0.5674199862463242</span></code></pre><p>由结果可见，数值引起的差别被放大了，但同时也保留了余弦相似度的反映变化趋势的特征。</p><h2 id="汉明距离（Hamming-distance）"><a href="#汉明距离（Hamming-distance）" class="headerlink" title="汉明距离（Hamming distance）"></a>汉明距离（Hamming distance）</h2><p>最好理解的一个：字符串之间<strong>对应位不同</strong>的数量，比如“110”和“111”的汉明距离为1，可以用在信号处理上，如果是在向量对比上效率就显得有点低了。</p><h2 id="曼哈顿距离（Manhattan-Distance）"><a href="#曼哈顿距离（Manhattan-Distance）" class="headerlink" title="曼哈顿距离（Manhattan Distance）"></a>曼哈顿距离（Manhattan Distance）</h2><h3 id="定义-4"><a href="#定义-4" class="headerlink" title="定义"></a>定义</h3><p>原文作者在这里提到了<code>刘昊然</code>原来他在唐探里提到过<code>曼哈顿计量法</code>。</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200728145702.jpg" alt="唐探里和作法一样的曼哈顿计量法" style="zoom:67%;" /><p>那曼哈顿距离又是什么呢，可以看这张图：</p><p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200728145953.jpg" alt="曼哈顿距离"></p><p>想象一下你是一个出租车司机，在曼哈顿街头，如果你想从A到B点，理论上最短距离应是直线距离，而实际上你不可能穿过一栋栋房屋直接到达B。曼哈顿距离表示的是你实际驾驶出租车从A到B的距离，该距离等于两个点在标准坐标系上的<strong>绝对轴距</strong>总和。用公式表示即<br>$$<br>\mathrm{d}<em>{12}=\sum</em>{k=1}^{n}\left|\mathrm{x}<em>{1 k}-x</em>{2 k}\right|<br>$$</p><h3 id="实现-4"><a href="#实现-4" class="headerlink" title="实现"></a>实现</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">Manhattan</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    d <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> a<span class="token punctuation">,</span> b <span class="token keyword">in</span> zip<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        d <span class="token operator">+=</span> a <span class="token operator">-</span> b    <span class="token keyword">return</span> abs<span class="token punctuation">(</span>d<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 取绝对值</span>V_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>V_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span>V_z <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>Manhattan<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 5</span><span class="token keyword">print</span><span class="token punctuation">(</span>Manhattan<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 6</span></code></pre><h2 id="切比雪夫距离（Chebyshev-Distance）"><a href="#切比雪夫距离（Chebyshev-Distance）" class="headerlink" title="切比雪夫距离（Chebyshev Distance）"></a>切比雪夫距离（Chebyshev Distance）</h2><h3 id="定义-5"><a href="#定义-5" class="headerlink" title="定义"></a>定义</h3><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200728152528.png" alt="国际象棋棋盘上的切比雪夫距离" style="zoom:80%;" /><p>我们可以通过观察这个国际象棋棋盘来理解切比雪夫距离，国王走到棋盘上任意一点的步数，只和坐标差值中较大者有关。</p><p>更科学地定义为</p><blockquote><p>切比雪夫距离：设平面空间内存在两点，它们的坐标为$(x_1,y_1)，(x_2,y_2)$ 则$is=max(|x_1−x_2|,|y_1−y_2|) $。即两点横纵坐标差的最大值 。$dis=max(AC,BC)=AC=4$。两个n维向量$(x_{11},x_{12},…,x_{1n})$与 $b(x_{21},x_{22},…,x_{2n})$间的切比雪夫距离：$d_{a b}=\max \left(\left|x_{1 i}-x_{2 i}\right|\right)$</p></blockquote><p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200728153839.png" alt="AC为两点的切比雪夫距离"></p><h3 id="实现-5"><a href="#实现-5" class="headerlink" title="实现"></a>实现</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">Chebyshev</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    d <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>d<span class="token punctuation">,</span> <span class="token operator">-</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># np.maximum(a, -a)这一步相当于在取绝对值</span>V_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>V_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span>V_z <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>Chebyshev<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 3</span><span class="token keyword">print</span><span class="token punctuation">(</span>Chebyshev<span class="token punctuation">(</span>V_x<span class="token punctuation">,</span> V_z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 10</span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>当然还有别的诸多距离，如闵可夫斯基距离，标准欧式距离。但是考虑到后续工作可能主要放在向量相似度的比较上，考虑使用余弦相似度相关的计算公式更合理。</p><p><strong>以上。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识嵌入 </tag>
            
            <tag> 向量 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何申请GitHub学生包</title>
      <link href="/2020/07/22/guan_yu_github_xue_sheng_bao/"/>
      <url>/2020/07/22/guan_yu_github_xue_sheng_bao/</url>
      
        <content type="html"><![CDATA[<p>事情是这样的，刚打开Pycharm出现了这样的一幕：</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200722181810.png" alt="证书他又双叒过期了" style="zoom:50%;" /><p>遂想找个方法再续上一续，结果发现了Jetbrain其实开放了学生免费使用Pycharm开发，网址<a href="https://sales.jetbrains.com/hc/zh-cn/articles/207154369-%E5%AD%A6%E7%94%9F%E6%8E%88%E6%9D%83%E7%94%B3%E8%AF%B7%E6%96%B9%E5%BC%8F" target="_blank" rel="noopener">戳我</a></p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200722181957.png" alt="JetBrain上的申请说明" style="zoom:67%;" /><p>这才意识到我不就是学生吗！遂准备申请，点进去看到了这样的选项：</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200722182653.png" alt="又看到我们的老朋友Github" style="zoom:67%;" /><p>原来GitHub为学生准备了专门的开发包</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200722191656.png" style="zoom:50%;" /><p>内容很丰富，都列举不完，<a href="https://education.github.com/pack" target="_blank" rel="noopener">戳我查看</a>，来一起看看如何申请这个包吧！</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>点击<code>Get the pack</code>，选择最左侧的<code>Get students benefits</code>。然后你会看到这样一个界面</p><p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200722190935.png" alt="第一步"></p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200722190944.png" alt="批注 2020-07-22 185645" style="zoom:80%;" /><p>如何填写我都放在图片里了。</p><p>点击提交你会看到<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200722191150.png" alt="哇要等18天呐（其实应该不用那么久）" style="zoom: 67%;" /></p><p>好，到这里我们开始等待吧，如果成功了我就把这篇发在别的地方。</p>]]></content>
      
      
      <categories>
          
          <category> 技巧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GitHub </tag>
            
            <tag> 白嫖 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何加速Github访问速度</title>
      <link href="/2020/07/22/ru_he_jia_su_github/"/>
      <url>/2020/07/22/ru_he_jia_su_github/</url>
      
        <content type="html"><![CDATA[<p>最近比较烦时常抽风的GitHub，搞得我不能愉快的<del>克隆</del>借鉴代码，再加上之前一直在用的鸡场场长跑路了，所以尝试改hosts来实现。</p><h2 id="首先把hosts放出来"><a href="#首先把hosts放出来" class="headerlink" title="首先把hosts放出来"></a>首先把hosts放出来</h2><p>路径是</p><pre><code>C:\Windows\System32\drivers\etc\hosts</code></pre><p>你可以把它复制到桌面上，增加三行，再覆盖原文件。</p><pre><code>140.82.112.3                github.com185.199.108.153             assets-cdn.github.com199.232.69.194              github.global.ssl.fastly.net</code></pre><p>当然这只是我的配置，你可以拿去用但是我不知道能不能奏效。</p><p>如果效果不好，你可以自己在<a href="https://www.ipaddress.com/" target="_blank" rel="noopener">ipaddress</a>上查找对应域名的ip然后进行更改。</p><p>值得注意的是第二个加速域名有多个ip，任选一个即可。</p><h2 id="到这里还没完"><a href="#到这里还没完" class="headerlink" title="到这里还没完"></a>到这里还没完</h2><p>打开CMD，输入</p><pre><code>ipconfig /flushdns</code></pre><p>回车后执行刷新本地DNS缓存数据。</p><p>试试看访问我的<a href="https://github.com/Cliccker" target="_blank" rel="noopener">个人主页</a>，如果能快速加载出来就说明奏效了。</p><h2 id="但是"><a href="#但是" class="headerlink" title="但是"></a>但是</h2><p>访问速度是快了不少，下载还是龟速怎么办？</p><p>一种方法是在码云上新建一个仓库，然后把Repo搬过来下载，个人觉得这样做有点麻烦。</p><p>另一种方法比较推荐，就是利用文件代下载服务，如<a href="https://shrill-pond-3e81.hunsh.workers.dev/" target="_blank" rel="noopener">https://shrill-pond-3e81.hunsh.workers.dev/</a></p><p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200722162047.png" alt="加速下载"></p><p>感谢热衷于分享的程序⚪们！</p>]]></content>
      
      
      <categories>
          
          <category> 技巧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GitHub </tag>
            
            <tag> 加速 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《算法设计与分析课程》笔记</title>
      <link href="/2020/07/19/xue_suan_fa/"/>
      <url>/2020/07/19/xue_suan_fa/</url>
      
        <content type="html"><![CDATA[<h2 id="1-1-算法的基本概念"><a href="#1-1-算法的基本概念" class="headerlink" title="1.1__算法的基本概念"></a>1.1__算法的基本概念</h2><p>算法的重要属性——<code>正确</code>和<code>高效</code></p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200719143345.png" alt="时间复杂度" style="zoom:50%;" /><h2 id="1-2-算法举例"><a href="#1-2-算法举例" class="headerlink" title="1.2__算法举例"></a>1.2__算法举例</h2><h3 id="局部高点"><a href="#局部高点" class="headerlink" title="局部高点"></a>局部高点</h3><p>定义：存在列表$A$，若$A[i-1] \leq A[i] \geq A[i+1]$，则称$A[i]$为局部高点。不是所有序列都有局部高点，这里限制边界条件$A[-1] = A[n]= -\infty$。</p><h4 id="简单算法："><a href="#简单算法：" class="headerlink" title="简单算法："></a>简单算法：</h4><p>找出数列中任意一个局部高点</p><p>逐个索引，比较前后元素之间的大小</p><ul><li>最好的情况：第一个元素就是局部高点 <code>1次</code></li><li>最坏的情况：最后一个元素才是局部高点<code>n次</code></li></ul><p><font color="#4590a3" size="4px">算法分析应考虑最坏的情况</font>，实际分析中应尽量忽略数据的分布</p><p>所以简单算法的效率事$O(n)$，函数是一个单调递增的线性函数</p><h4 id="更高效的算法："><a href="#更高效的算法：" class="headerlink" title="更高效的算法："></a>更高效的算法：</h4><p>考虑每次查找都缩小查找的范围</p><p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200719160534.png" alt="三种可能存在的情况"></p><p>从中间的元素开始查找，可以在一次比较后，缩小一半的搜索范围（二分法）</p><p>算法的效率为$O(log_2n)$</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何将MarkDown笔记导出至知乎</title>
      <link href="/2020/07/16/ru_he_jiang_markdown_dao_chu_zhi_zhi_hu/"/>
      <url>/2020/07/16/ru_he_jiang_markdown_dao_chu_zhi_zhi_hu/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 2019-11-26</span><span class="token keyword">import</span> re<span class="token keyword">import</span> sys<span class="token keyword">def</span> <span class="token function">replace</span><span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> output_file_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        pattern1 <span class="token operator">=</span> r<span class="token string">"\$\$\n*([\s\S]*?)\n*\$\$"</span>        new_pattern1 <span class="token operator">=</span> r<span class="token string">'\n&lt;img src="https://www.zhihu.com/equation?tex=\1" alt="\1" class="ee_img tr_noresize" eeimg="1">\n'</span>        pattern2 <span class="token operator">=</span> r<span class="token string">"\$\n*(.*?)\n*\$"</span>        new_pattern2 <span class="token operator">=</span>r<span class="token string">'\n&lt;img src="https://www.zhihu.com/equation?tex=\1" alt="\1" class="ee_img tr_noresize" eeimg="1">\n'</span>        f <span class="token operator">=</span> open<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>        f_output <span class="token operator">=</span> open<span class="token punctuation">(</span>output_file_name<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>        all_lines <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>        new_lines1 <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>pattern1<span class="token punctuation">,</span> new_pattern1<span class="token punctuation">,</span> all_lines<span class="token punctuation">)</span>        new_lines2 <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>pattern2<span class="token punctuation">,</span> new_pattern2<span class="token punctuation">,</span> new_lines1<span class="token punctuation">)</span>        f_output<span class="token punctuation">.</span>write<span class="token punctuation">(</span>new_lines2<span class="token punctuation">)</span>        f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>        f_output<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    file_name <span class="token operator">=</span> <span class="token string">'original_version.md'</span>    file_name_pre <span class="token operator">=</span> file_name<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    output_file_name <span class="token operator">=</span> <span class="token string">"zhihu_version.md"</span>    replace<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> output_file_name<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Trans from {} to {}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> output_file_name<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>放在同一文件夹下，将markdown文件改名为’original_version.md’，运行就可以了</p>]]></content>
      
      
      <categories>
          
          <category> 技巧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MarkDown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读论文——On2Vec：基于嵌入的本体群体关系预测</title>
      <link href="/2020/07/16/2020_7_16_du_lun_wen_on2vec_ji_yu_qian_ru_de_ben_ti_qun_ti_guan_xi_yu_ce/"/>
      <url>/2020/07/16/2020_7_16_du_lun_wen_on2vec_ji_yu_qian_ru_de_ben_ti_qun_ti_guan_xi_yu_ce/</url>
      
        <content type="html"><![CDATA[<h1 id="读论文——On2Vec：基于嵌入的本体群体关系预测"><a href="#读论文——On2Vec：基于嵌入的本体群体关系预测" class="headerlink" title="读论文——On2Vec：基于嵌入的本体群体关系预测"></a>读论文——On2Vec：基于嵌入的本体群体关系预测</h1><p><em>原标题*：On2Vec: Embedding-based Relation Prediction for Ontology Population  *<a href="https://arxiv.org/abs/1809.02382" target="_blank" rel="noopener">来源</a></em> <a href="https://github.com/muhaochen/on2vec" target="_blank" rel="noopener"><em>代码</em></a></p><h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><h3 id="目标领域"><a href="#目标领域" class="headerlink" title="目标领域"></a>目标领域</h3><p>本体填充（Ontology population），指将原始信息（可以是非结构化、半结构化或者结构化的数据）转换为本体实例的过程。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>现有的研究已经能将基于翻译的知识嵌入模式应用到实例层级的图谱中，实现较好的填充效果。相比于实例图谱，本体视图中的关系事实包含了更多复杂的语义关系，包括<code>可传递性</code>，<code>对称性</code>和<code>层次关系</code>。这种关系对于现有的嵌入模式来说过于复杂，且直接应用不可行。在TransE中我们用能量方程$S_{r}(\mathbf{s}, \mathbf{t})$去衡量一个三元组的可信度，函数值越小，代表描述就越准确。<br>$$<br>S_{r}(\mathbf{s}, \mathbf{t})=|\mathbf{s}+\mathbf{r}-\mathbf{t}|<br>$$<br>文章提出这种能量方程会导致如图所示的问题：</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/批注 2020-07-16 162227.png" alt="图1" title="图1" style="zoom:50%;" /><ul><li><p>Case1：$\boldsymbol {A,B,C}$是三个概念$A,B,C$的嵌入，假设<br>$$<br>\boldsymbol {A+r\approx B，B+r\approx C}<br>$$<br>即$r$是一种具有传递性的关系，按照传递性的原则应当有：<br>$$<br>\boldsymbol {A+r\approx C}<br>$$<br>然而事实上：<br>$$<br>\boldsymbol {A + r\ne C}<br>$$<br>这个结论很容易就能从图中观察出来。</p></li><li><p>Case2：$\boldsymbol {E,F}$是两个概念$E,F$的嵌入，假设：<br>$$<br>\boldsymbol {E+r\approx F}<br>$$<br>且$r$为对称性关系，则应有：</p><p>$$<br>\boldsymbol {F+r\approx E}<br>$$</p><p>然而事实上：<br>$$<br>\boldsymbol {F+r\ne E}<br>$$<br>这是因为向量$\boldsymbol r \ne 0$。</p></li></ul><h3 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h3><p>由两个模型组件组成的On2vec，包括：</p><ol><li>Component-specific Model （组件特定模型）将概念和关系编码嵌入低维空间，且不丢失相关属性；</li><li>Hierarchy Model  （层次模型）集中处理层级关系。</li></ol><h2 id="技术路线"><a href="#技术路线" class="headerlink" title="技术路线"></a>技术路线</h2><h3 id="符号及其含义"><a href="#符号及其含义" class="headerlink" title="符号及其含义"></a>符号及其含义</h3><table><thead><tr><th align="center">字符</th><th align="center">含义</th><th align="center">示例</th></tr></thead><tbody><tr><td align="center">$G(C,R）$</td><td align="center">一个图谱</td><td align="center"></td></tr><tr><td align="center">$C$</td><td align="center">一系列的概念</td><td align="center"></td></tr><tr><td align="center">$R$</td><td align="center">一系列语义关系</td><td align="center"></td></tr><tr><td align="center">$T=(s,r,t)$</td><td align="center">一个三元组</td><td align="center"></td></tr><tr><td align="center">$\boldsymbol s$</td><td align="center">vectors of source</td><td align="center"></td></tr><tr><td align="center">$\boldsymbol r$</td><td align="center">vectors of relation</td><td align="center"></td></tr><tr><td align="center">$\boldsymbol t$</td><td align="center">vectors of target</td><td align="center"></td></tr><tr><td align="center">$R_{tr}$</td><td align="center">传递关系</td><td align="center">如isConnectedTo</td></tr><tr><td align="center">$R_s$</td><td align="center">对称关系</td><td align="center">如isMarriedTo</td></tr><tr><td align="center">$R_h$</td><td align="center">层级关系</td><td align="center"></td></tr><tr><td align="center">$R_r$</td><td align="center">将粗概念划分为细概念的细化关系</td><td align="center">如hasChild</td></tr><tr><td align="center">$R_c$</td><td align="center">将细概念划分到粗概念的强制关系</td><td align="center">如isLocatedIn</td></tr><tr><td align="center">$R_o$</td><td align="center">其他关系</td><td align="center"></td></tr></tbody></table><p>我可以用不同的数学表达式展示各种关系，如传递关系$R_{tr}$</p><p>$$<br>given: r \in R_{tr} \ c_1,c_2,c_3 \in G \ if:(c_1,r,c_2),(c_2,r,c_3) \in G<br>\ then : (c_1,r,c_3) \in G<br>$$</p><h3 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h3><h4 id="Component-specific-Model"><a href="#Component-specific-Model" class="headerlink" title="Component-specific Model"></a>Component-specific Model</h4><h5 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h5><p>这个名字不知道怎么翻译合适。暂时称为<code>特定组件模型</code>。</p><p>文章在这里认为，<code>关系投影函数</code>$f_r$在投影时，就已经把复杂关系中的概念放在了有冲突的位置上。为了解决这个两个问题，CSM提出了用两个不相同的$f_r$，去区别同一概念在不同三元组中的嵌入。仔细解释一下就是，对于同一个概念，在不同三元组中的<code>组分</code>会不同，因此在衡量一个三元组的<code>可信度</code>时，需要对该三元组中概念的<code>嵌入</code>做一定的调整才能解决这些冲突。据此文章提出了一种新的衡量可信度方程$S_{d}(T)$</p><p>$$<br>S_{d}(T)=| f_{1, r}(\mathbf{s})+\mathbf{r}-f_{2, r}(\mathbf{t}) \mid<br>$$</p><p>式中的$f_{1,r}(x),f_{2,r}(x)$是作用于头尾概念的不同<code>组分投影函数</code>，后文提到了这两个函数实际就是两个$k \times k $的矩阵，这两个矩阵的形式由概念在<strong>不同三元组中的组分</strong>决定。</p><blockquote><p>The forms of $f_{1,r}$and $f_{2,r}$ are decided particularly by the techniques to differentiate the concept encoding under different contexts of relations.  </p></blockquote><p>文章还提到$S_{d}$在消除冲突的同时，还能用来实现挖掘本体中隐藏的关系。现在我们在处理Case 1时，就能把在不同三元组中的$B$放在不同的位置。对于Case 2 ，可以让$E，F$互换位置。</p><h5 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h5><p>CSM的目标是最小化能量函数，也就是增加所有三元组的可信度。和别的模型选择<code>实体</code>做负面样本不一样的是，CSM选择<code>关系</code>来做负面的样本，由此提出loss：</p><p>$$<br>\begin{aligned}<br>S_{\mathrm{CSM}}(G)=&amp; \sum_{(s, r, t) \in G}\left[\left|f_{1, r}(\mathbf{s})+\mathbf{r}-f_{2, r}(\mathbf{t})\right|\right.\left.-\left|f_{1, r}(\mathbf{s})+\mathbf{r}^{\prime}-f_{2, r}(\mathbf{t})\right|+\gamma_{1}\right]_{+}<br>\end{aligned}<br>$$</p><p>式中的$r’$是一个<code>并不能连接</code>$s$和$t$的<code>随机选取</code>的关系，$\gamma_{1}$是一个正矩阵。学习目的是为了得到更小的$S_{CSM}$</p><h4 id="Hierarchy-Model"><a href="#Hierarchy-Model" class="headerlink" title="Hierarchy Model"></a>Hierarchy Model</h4><h5 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h5><p>对于层次关系，这篇文章提到了我读的<a href="https://zhuanlan.zhihu.com/p/156791237" target="_blank" rel="noopener">另一篇论文</a>中对层级关系的处理方法，就是让他们在向量空间上尽量聚集。如图</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200717125248.png" title ="图2 上一篇文章提到的分组技术" style="zoom: 67%;" /><p>文章提出较为精细的概念，比如”person”，可以参与多个关系事实，这就导致了在嵌入时一个关系事实容易受到其他关系事实的影响，降低了三元组的可信度。HM要做的是将每一个精细概念的嵌入更加紧密的<code>融合</code>在一起。为了做到这一点，文章提出了一种<code>精炼</code>的操作，如图：</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200717151516.png" alt="图3 ‘精炼’操作" style="zoom:67%;" /><p>这一步骤是为了让所有<code>直接</code>相关的概念聚集，形成一个个<code>群体</code>。<br>举例说明：</p><ul><li><p>设$(c_1,isA,c_2),(c_2,isA,c_3),(c_4,isA,c_3),(c_5,isA,c_3) \in G$</p></li><li><p>则有$\sigma(c_3,isA) = [c_2,c_4,c_5]$</p></li><li><p>虽然$(c_1,isA,c_2),(c_2,isA,c_3)$得到$(c_1,isA,c_3)$，但是这里认为$c_1$并不与$c_3$直接相关，故$c_1 \notin\sigma(c_3,isA)$</p></li></ul><p>这样做使得<code>群体</code>的数量大大增加，<code>群体</code>之间的联系减少，减少了关系事实之间的干扰。同时也要考虑，在某一群体中处于中心的概念嵌入，在另一群体中将处于边缘，所以也需要对其嵌入做适当调整。</p><p>据此列出能量方程：<br>$$<br>\begin{aligned}<br>S_{h m}(G) &amp;=\sum_{r \in R_{r}} \sum_{s \in C} \sum_{t \in \sigma(s, r)} \omega\left(f_{1, r}(\mathbf{s})+\mathbf{r}, f_{2, r}(\mathbf{t})\right) \<br>&amp;+\sum_{r \in R_{c}} \sum_{t \in C} \sum_{s \in \sigma(t, r)} \omega\left(f_{2, r}(\mathbf{t})-\mathbf{r}, f_{1, r}(\mathbf{s})\right)<br>\end{aligned}<br>$$<br>$f_{1,r}和f_{2,r}$就是上一节写到的调整函数。$\omega (x)$是用来计算两个向量的相似度的单调递增的函数，算法中直接计算两个向量的余弦距离，余弦距离越小，余弦相似度越高。第一行计算的是所有<code>直接细化关系</code>的三元组的偏差，第二行计算的是所有<code>直接强制关系</code>的三元组的偏差，相加得到整个图谱的偏差。</p><h5 id="优化-1"><a href="#优化-1" class="headerlink" title="优化"></a>优化</h5><p>$$<br>\begin{aligned}<br>S_{\mathrm{HM}}(G) &amp;=\sum_{r \in R_{r}} \sum_{s \in C} \sum_{t \in \sigma(s, r) \wedge \ t^{\prime} \notin \sigma(s, r)} S_{h r} \<br>&amp;+\sum_{r \in R_{c}} \sum_{t \in C} \sum_{s \in \sigma(t, r) \wedge \ s^{\prime} \notin \sigma(t, r)} S_{h c}<br>\end{aligned}<br>$$</p><p>$s’$和$t’$在这里做负面样本，其中</p><p>$$<br>S_{h r}=\left[\omega\left(f_{1, r}(\mathbf{s})+\mathbf{r}, f_{2, r}(\mathbf{t})\right)-\omega\left(f_{1, r}(\mathbf{s})+\mathbf{r}, f_{2, r}\left(\mathbf{t}^{\prime}\right)\right)+\gamma_{2}\right]_{+}<br>$$</p><p>$$<br>S_{h c}=\left[\omega\left(f_{2, r}(\mathbf{t})-\mathbf{r}, f_{1, r}(\mathbf{s})\right)-\omega\left(f_{2, r}(\mathbf{t})-\mathbf{r}, f_{1, r}\left(\mathbf{s}^{\prime}\right)\right)+\gamma_{2}\right]_{+}<br>$$</p><h3 id="学习流程"><a href="#学习流程" class="headerlink" title="学习流程"></a>学习流程</h3><p>学习的目标是联合损失最小，联合损失的表达式如下<br>$$<br>J(\theta)=S_{\mathrm{CSM}}+\alpha_{1} S_{\mathrm{HM}}+\alpha_{2} S_{\mathrm{N}}<br>$$</p><ul><li>$\theta$ 是包括嵌入向量和投影矩阵的一系列的参数的集合</li><li>$\alpha_{1} S_{\mathrm{HM}}$中的$\alpha_1$用来调整两个模型的权重</li><li>$\alpha_1S_N$中的$\alpha_1$是一个大于零小于等一的数，$S_N$用来对嵌入和投影施加约束，防止出现向量趋向于无限大的情况。其形式如下</li></ul><img src="C:\Users\76084\Desktop\20200720152243.png" alt="$S_N$" style="zoom: 50%;" /><p>最后给出了具体算法流程如图</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200717171122.png" alt="图4 算法" style="zoom:67%;" /><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200717172910.png" alt="图5 数据集" style="zoom:67%;" /><p>在实验中，这个模型被用来做<code>关系预测</code>和<code>关系识别</code>。关系预测准确率在90%左右，关系识别的准确率波动较大，最高有98%，最低73%</p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>这篇论文看的我蛮痛苦的，因为里面好多用词都不是那么精准，而且也没有合适的图例表达算法逻辑，和之前发出来那篇差了好多，许多地方并不能说服我，有时间再看看他的源码吧。果然好论文一定是容易读的论文！</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 本体 </tag>
            
            <tag> 知识嵌入 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>烧卖有梗</title>
      <link href="/2020/07/14/146/"/>
      <url>/2020/07/14/146/</url>
      
        <content type="html"><![CDATA[<p>从今年开始，学生们最恐怖的噩梦从梦到上学没穿裤子变成了网课没关麦。</p>]]></content>
      
      
      <categories>
          
          <category> 想法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 一个小笑话 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《知识图谱：方法、实践与应用》阅读笔记——知识图谱表示与建模（2）</title>
      <link href="/2020/07/14/zhi_shi_tu_pu_fang_fa_shi_jian_yu_ying_yong_yue_du_bi_ji_zhi_3/"/>
      <url>/2020/07/14/zhi_shi_tu_pu_fang_fa_shi_jian_yu_ying_yong_yue_du_bi_ji_zhi_3/</url>
      
        <content type="html"><![CDATA[<p>距离上一篇读书笔记已经有一段日子了，中间打了很多代码，也摸了很多🐟。有时候还是比较细化打代码的，感觉比码字有意思。但是有意思的事做太多就不会有积累了，所以接着填这个坑叭！</p><h2 id="互联网时代的语义网知识表示框架"><a href="#互联网时代的语义网知识表示框架" class="headerlink" title="互联网时代的语义网知识表示框架"></a>互联网时代的语义网知识表示框架</h2><p>上一篇文章中提到的“语义网”让知识表示迎来了新的春天，不过也出现了新的挑战——标准语言在哪里？HTML和XML已经跟不上这个时代了（时代变了，大人）。W3C提出了新的标准语言RDF和OWL，我们一起来欣赏一下吧。</p><h3 id="核心成员RDF"><a href="#核心成员RDF" class="headerlink" title="核心成员RDF"></a>核心成员RDF</h3><p>RDF中的知识永远是以三元组的形式呈现出来，就是(subject,predicate,object)， 亦即（主语，谓语，宾语）。我们可以把它看成一个传统意义上的句子结构中的主谓宾，比如“我喜欢吃冰淇淋，吃完就长肉”👉（我，喜欢，吃冰淇淋）（我，长，肉）。同时我们也可以用（我，在什么时候吃雪糕，“12点”^xsd:date）表示“我在12点吃了雪糕”。从中我们可以看出，RDF中的主语一定是一个个体（individual），书中也解释了个体是类的实例，比如我是人“类”的一个实例，谓语表示属性，宾语可以是个体也可是实例。</p><p>我们拿我怎么变胖来构建来建立一个图谱，如下</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-153445.png" alt=""></p><p>我变胖的一个图谱</p><p>再来把他写成英文，如下</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-153804-1.png" alt=""></p><p>a KG of my growing weights</p><p>由于在RDF中的主谓宾都有一个全局标识，所以我们再给这个图谱中的元素加点料</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-155352-1.png" alt=""></p><p>看起来是不是更像回事了？</p><p>全局URL可以简化为前缀URL，当然也可以出现没有前缀的空白节点（BlankNode），长这样</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-160905.png" alt=""></p><p>空白节点可以代入你我他哦</p><h3 id="开放世界假设"><a href="#开放世界假设" class="headerlink" title="开放世界假设"></a>开放世界假设</h3><p>这个假设听起来是不是很酷呢？实际上他比听起来更酷。开放世界假设使得RDF图谱里的知识可以是不完整的，例如我喜欢吃冰激凌，并不意味着我只喜欢吃冰激凌，雪糕当然也是不错的选择😋，(i,enjoy,ice-cream)代表冰淇淋至少是我的一个爱好！采用开放世界假设有什么好处呢？答案是可以实现分布式存储，像这样：</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-162100.png" alt=""></p><p>我喜欢冰淇淋&amp;冰淇淋是光明牌的</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-162503.png" alt=""></p><p>我喜欢吃光明的冰淇淋</p><h3 id="RDF-Schema——RDFS"><a href="#RDF-Schema——RDFS" class="headerlink" title="RDF Schema——RDFS"></a>RDF Schema——RDFS</h3><p>RDFSchema（RDF模式，简称RDFS）提供了对类和属性的简单描述，包括上下级关系（subclass_of)，定义域(domian)，值域（range）等。这一步我直接上书上的图：</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-163732.png" alt=""></p><p>可谓图糙理不糙，上面是本体视图，下面是实例视图</p><hr><h2 id="主力成员OWL🦉"><a href="#主力成员OWL🦉" class="headerlink" title="主力成员OWL🦉"></a>主力成员OWL🦉</h2><p>RDF(S)可以表示一些简单的语义，但是如果场景更加复杂的化，RDF就不太行了。RDF本身缺少很多常用的特征，把书中写出来的几个简单罗列：</p><p>1.无法准确的描述属性的定义、特征；</p><p>2.无法描述类、个体属性是否等价（是我杀了我？）</p><p>3.基数约束，即一个人不可能有两个爸爸（出了于谦儿子郭小宝）</p><p>总之，RDF在描述事实的时候就像是一个年幼的孩子👶，很多事情很多关系他还不懂，我们需要一个更成熟的本体语言来替我们表达知识！</p><h3 id="OWL语言特征"><a href="#OWL语言特征" class="headerlink" title="OWL语言特征"></a>OWL语言特征</h3><p>OWL1.0有三个子语言，OWL Lite&lt;OWL DL&lt;OWL Full。书中写道这三者选择的原则</p><blockquote><p>●选择OWL Lite还是OWL DL主要取决于用户需要整个语言在多大程度上给出约束的可表达性；</p><p>●选择OWL DL还是OWL Full主要取决于用户在多大程度上需要RDF的元模型机制，如定义类型的类型以及为类型赋予属性；</p><p>●当使用OWL Full而不是OWL DL时，推理的支持可能不能工作，因为目前还没有完全支持OWL Full的系统实现。</p></blockquote><p>OWL不是完全独立于RDF的，他们在很多地方都有相似之处，不过我觉得知道这个没用！</p><h3 id="OWL重要词汇"><a href="#OWL重要词汇" class="headerlink" title="OWL重要词汇"></a>OWL重要词汇</h3><ol><li>等价性声明</li><li>属性传递声明👉a大于b，b大于c 可以推出 a大于c</li><li>属性互逆声明 👉a大于b，b小于a 大于小于这两个属性互逆</li><li>属性的函数声明👉a的大写是A</li><li>属性的对称性声明👉a=b，b=a</li><li>属性的全称限定声明👉如：母亲一定是女人</li><li>属性的存在限定声明👉如：我一部分的文章发在知乎上</li><li>属性的基数限定声明👉如：我只能有“一个”父亲</li><li>相交的类声明👉如：妈妈是有孩子的人，即有孩子和人的交集</li></ol><p>这些词汇在书上写的很详细，这个笔记抄下来就没意思了。</p><h3 id="OWL版本"><a href="#OWL版本" class="headerlink" title="OWL版本"></a>OWL版本</h3><p>OWL2的三大子语言是OWL 2 RL、OWL 2 QL和OWL 2 EL，关于这三种语言的词汇，书中有写错的地方，需要去别处找更准确的总结。</p><hr><h2 id="语义Markup表示语言"><a href="#语义Markup表示语言" class="headerlink" title="语义Markup表示语言"></a>语义Markup表示语言</h2><p>语义网进一步定义了在网页中嵌入语义Markup的方法和表示语言。被谷歌知识图谱以及Schema.Org采用的语义Markup语言主要包括JSON-LD、RDFa和HTML5 MicroData。</p><p><strong>我似乎感觉到这本书不怎么样了，因为书里一直在罗列概念也没说要自己动手做。还是只看自己感兴趣的内容吧</strong></p><p><strong><em>To Be Continued</em></strong></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识图谱 </tag>
            
            <tag> owl </tag>
            
            <tag> rdf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《知识图谱：方法、实践与应用》阅读笔记——知识图谱概述</title>
      <link href="/2020/07/13/zhi_shi_tu_pu_fang_fa_shi_jian_yu_ying_yong_yue_du_bi_ji_zhi_2/"/>
      <url>/2020/07/13/zhi_shi_tu_pu_fang_fa_shi_jian_yu_ying_yong_yue_du_bi_ji_zhi_2/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是知识图谱？"><a href="#什么是知识图谱？" class="headerlink" title="什么是知识图谱？"></a>什么是知识图谱？</h2><p>一种用<strong>图模型</strong>(probabilistic graphic models)来描述知识和建模世界万物之间的关联关系的技术方法。由<strong>节点</strong>和<strong>边</strong>组成</p><h2 id="知识图谱的价值"><a href="#知识图谱的价值" class="headerlink" title="知识图谱的价值"></a>知识图谱的价值</h2><ol><li>辅助搜索</li><li>辅助问答</li><li>辅助大数据分析</li><li>辅助语言理解，人机之间的相互理解</li></ol><p><img src="https://pic4.zhimg.com/v2-c83e96721a4635920b7aac623783042f_b.png" alt=""></p><p>这道看似简单的题，机器却毫无办法。“到底谁大谁小？”</p><p>5.辅助设备互联，机器与机器之间的相互理解书中一直强调的辅助作用，是不是意味着知识图谱更像一种锦上添花的工具？</p><h2 id="一些知识图谱项目"><a href="#一些知识图谱项目" class="headerlink" title="一些知识图谱项目"></a>一些知识图谱项目</h2><p>freebase​</p><p>wikidata（需要梯子）</p><p><img src="https://pic4.zhimg.com/v2-8ef39dbe4682280e4814220dfcbc49d3_b.png" alt=""></p><p>如何构建一个规模化的知识图谱</p><p>值得注意的是阿里巴巴有自己的电商知识图谱，规模达到了百亿级别。</p><h2 id="知识图谱的技术流程"><a href="#知识图谱的技术流程" class="headerlink" title="知识图谱的技术流程"></a>知识图谱的技术流程</h2><ul><li>知识图谱采用更加规范而标准的概念模型、本题术语和语法格式来建模和描述数据</li><li>通过语义链接来增强数据之间的关系</li></ul><p>_就像是一张网。_知识图谱方法论涉及知识表示、知识获取、知识处理和知识利用多个方面。一般流程为：</p><ol><li>首先确定知识表示模型，然后根据数据来源选择不同的知识获取手段导入知识</li><li>接着综合利用知识推理、知识融合、知识挖掘等技术对构建的知识图谱进行质量提升，</li><li>最后根据场景需求设计不同的知知识访问与呈现方法，如语义搜索、问答交互、图谱可视化分析等。</li></ol><h3 id="1-知识来源"><a href="#1-知识来源" class="headerlink" title="1.知识来源"></a>1.知识来源</h3><p>有多种来源来获取知识，除了文本，我们还可以考虑结构化数据库、多媒体数据、传感器数据和人工众包。对于文本数据源，我们要用到<strong>自然语言处理技术。</strong>对于各种结构化数据库，<strong>需要将结构化数据定义到本体模型之间的语义映射，再通过编写语义翻译工具实现转化。</strong></p><h3 id="2-知识表示"><a href="#2-知识表示" class="headerlink" title="2.知识表示"></a><strong>2.知识表示</strong></h3><p>即用计算机符号来表述人类的语言</p><p><img src="https://pic2.zhimg.com/v2-9ef1ddd2692744e97469778a17e53765_b.png" alt=""></p><p>知识表示的产出目标</p><p><img src="https://pic1.zhimg.com/v2-c3c4263647d7b65e840280206d4be42c_b.png" alt=""></p><p>知识图谱分类</p><h3 id="3-知识抽取"><a href="#3-知识抽取" class="headerlink" title="3.知识抽取"></a>3.知识抽取</h3><p>知识抽取按任务划分可以分为概念抽取、实体识别、关系抽取、事件抽取和规则抽取等</p><p><img src="https://pic2.zhimg.com/v2-46f64c05ef7f4c2de99f6324ca7bda29_b.png" alt=""></p><p>知识抽取的划分</p><p>书中解释了远程监督的思想远程监督的思想是，利用一个大型的语义数据库自动获取关系类型标签。这些标签可能是含有噪声的，但是大量的训练数据在一定程度上可以抵消这些噪声。另外，一些工作通过多任务学习等方法将实体和关系做联合抽取。最新的一些研究则利用强化学习减少人工标注并自动降低噪声。如何减少人工标注，是我现阶段工作的重点。</p><h3 id="4-知识融合"><a href="#4-知识融合" class="headerlink" title="4.知识融合"></a>4.知识融合</h3><p>外部数据库合并到本体知识库时，需要解决两个问题</p><ol><li>通过模式层(?)的融合，将新的本体融入已有的本体库中，以及新旧本体的融合</li><li>数据层的融合，包括实体的指称、属性、关系和所属类别。</li></ol><p><strong>关键问题是如何避免实例以及关系的冲突问题，造成不必要的冗余</strong></p><p><em>文中提到的本体概念，这边没有太理解，需要另找专门的文献再熟悉熟悉</em></p><h3 id="5-知识图谱的补全和推理（重头戏"><a href="#5-知识图谱的补全和推理（重头戏" class="headerlink" title="5.知识图谱的补全和推理（重头戏)"></a>5.知识图谱的补全和推理（重头戏)</h3><h3 id="6-知识检索和知识分析"><a href="#6-知识检索和知识分析" class="headerlink" title="6.知识检索和知识分析"></a>6.知识检索和知识分析</h3><p>包括语义检索和智能问答</p><h2 id="知识图谱相关技术"><a href="#知识图谱相关技术" class="headerlink" title="知识图谱相关技术"></a>知识图谱相关技术</h2><p><img src="https://pic4.zhimg.com/v2-7793c97d516a7921e3efbda54397813f_b.png" alt=""></p><p>数据库与数据模型</p><p><img src="https://pic4.zhimg.com/v2-258314714963e49e9bb038c5ade3ce93_b.png" alt=""></p><p>知识问答</p><p><img src="https://pic2.zhimg.com/v2-a47b6ecd00ed64de048f2419e3aebbd1_b.png" alt=""></p><p>知识推理</p><p>基于表示学习的知识图谱推理研究的主要研究趋势是，一方面提高表示学习结果对知识图谱中含有的语义信息的捕捉能力，目前的研究多集中在链接预测任务上，其他推理任务有待跟进研究；另一方面是利用分布式表示作为桥梁，将知识图谱与文本、图像等异质信息结合，实现信息互补以及更多样化的综合推理。如果说我们人的思维是一个已经存在的知识图谱，那么我们在学习知识的时候，基于知识表示的学习方法一定是更快的，相比于基于规则的推理而言，知识来源的渠道更广泛，更丰富，更能激发“兴趣”。后面还写到了推荐系统与去中心化，这里暂且不论。</p><p><strong><em>第一章 完</em></strong></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识图谱 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《知识图谱：方法、实践与应用》阅读笔记——知识图谱表示与建模（1）</title>
      <link href="/2020/07/13/zhi_shi_tu_pu_fang_fa_shi_jian_yu_ying_yong_yue_du_bi_ji_zhi/"/>
      <url>/2020/07/13/zhi_shi_tu_pu_fang_fa_shi_jian_yu_ying_yong_yue_du_bi_ji_zhi/</url>
      
        <content type="html"><![CDATA[<p>上一篇文章中我们介绍了什么是知识图谱，而这一篇讲述了知识图谱的表示和建模方法。和编程之前需要选择平台一样，知识图谱的建模也需要我们来选择一种方法。本章主要讲述了如何使用这些方法对知识进行建模。</p><h2 id="1-什么是知识表示"><a href="#1-什么是知识表示" class="headerlink" title="1.什么是知识表示"></a>1.什么是知识表示</h2><p>知识表示的五大用途和特点<strong>客观事物的机器标示</strong>（A KR is a Surrogate），即知识表示首先需要定义客观实体的机器指代或指称。 <strong>一组本体约定和概念模型</strong>（A KR is a Set of Ontological Commitments），即知识表示还需要定义用于描述客观事物的概念和类别体系。 <strong>支持推理的表示基础</strong>（A KR is a Theory of Intelligent Reasoning），即知识表示还需要提供机器推理的模型与方法。 <strong>用于高效计算的数据结构</strong>（A KR is a medium for Efficient Computation），即知识表示也是一种用于高效计算的数据结构。 <strong>人可理解的机器语言</strong>（A KR is a Medium of Human Expression），即知识表示还必须接近于人的认知，是人可理解的机器语言。再来梳理一下知识表示发展的脉络</p><p><img src="https://pic2.zhimg.com/v2-a1c0be286efd3f1dcd5c86f8a1b6287d_b.png" alt="" title="知识表示发展脉络"></p><p>知识表示发展脉络</p><p>Q：为什么要引入向量的概念？A: 简单来讲，向量能够表示更多字符无法表示的隐藏的知识，且更易于推理。</p><hr><h3 id="2-早期的一些表示方法"><a href="#2-早期的一些表示方法" class="headerlink" title="2.早期的一些表示方法"></a>2.早期的一些表示方法</h3><ul><li><strong>一阶谓词逻辑</strong></li></ul><p><strong><em>第一步：列出一些基本逻辑</em></strong></p><p>COMPUTER（x）：x是计算机系的学生。LIKE（x，y）：x喜欢y。HIGHER（x，y）：x比y长得高。</p><p><strong><em>第二步：将个体代入谓词中</em></strong></p><p>这里涉及的个体有：张晓辉（zhangxh），编程序（programming），李晓鹏（lixp），以函数father（lixp）表示李晓鹏的父亲。</p><p><img src="https://www.zhihu.com/equation?tex=COMPUTER(zhangxh)%20%2C~LIKE(zhangxh%2C%20programming)%20%20%2CHIGHER(lip%2C%20father%EF%BC%88lixp%EF%BC%89)" alt="COMPUTER(zhangxh) ,~LIKE(zhangxh, programming)  ,HIGHER(lip, father（lixp）)">)COMPUTER(zhangxh) ,~LIKE(zhangxh, programming) ,HIGHER(lip, father（lixp）)</p><p><strong><em>第三步：根据语义，用逻辑联接词将它们联接起来，就得到了表示上述知识的谓词公式</em></strong><img src="https://www.zhihu.com/equation?tex=COMPUTER(zhangxh)%20%E2%88%A7LIKE(zhangxh%2C%20programming)" alt="COMPUTER(zhangxh) ∧LIKE(zhangxh, programming)"></p><p>COMPUTER(zhangxh) ∧LIKE(zhangxh, programming)</p><p><em>张晓辉是一个计算机系的学生，他喜欢编程</em></p><p>HIGHER(lixp, father( lixp))</p><p><em>李晓鹏比他父亲长得高</em></p><ul><li><strong>霍恩子句和霍恩逻辑</strong></li></ul><p><strong>霍恩子句（Horn Clause）得名于逻辑学家Alfred Horn[6]。一个子句是文字的析取。霍恩子句是带有最多一个肯定（positive）文字的子句，肯定文字指的是没有否定符号的文字。例如，Øp1∨…∨Øpn∨ q是一个霍恩子句，它可以被等价地写为（p1∧…∧pn）→ q。Alfred Horn于1951年撰文指出这种子句的重要性。</strong>这一段书里讲的内容属实没看明白，但是也不是特别重要，因为在知识表示方面他已经是过去式了！</p><ul><li><strong>语义网络</strong></li></ul><p>语义网络在形式上式一个带有标识的有向图，由节点和连接弧组成。如图</p><p><img src="https://pic1.zhimg.com/v2-b1be71183c8a9d116fc9fe7e66d25528_b.png" alt=""></p><p>语义网络的构成</p><p>语义网络的<strong>缺点</strong>是</p><ol><li>同一段知识可能有多种多样的表示形式。不同的表示形式会提高处理不同语义网络的复杂性。</li><li>如果你想要理解一个语义网络的含义，那你只能依靠其处理程序。即语义网络缺少一套公认的形式表示体系。这会产生什么样的影响呢？举个栗子，假如全世界各个国家的人只说自己本国的语言，那跨国交流就只能依靠打手势了，使得知识表示非常容易产生偏差。</li></ol><p><strong><em>“我对着她竖起了中指，她却以为我爱上了她”</em></strong></p><ul><li><strong>框架</strong></li></ul><p><strong>其理论的基本思想是：认为人们对现实世界中各种事物的认识都以一种类似于框架的结构存储在记忆中。</strong></p><p><img src="https://pic3.zhimg.com/v2-71697617962190b91b396e34f73f9ef6_b.png" alt=""></p><p>一个框架的实例</p><p>我们可以看到框架中有很多默认值，这种默认值会大大增加推理的难度。</p><ul><li><strong>描述逻辑</strong></li></ul><p><strong>描述逻辑可以被看成是利用一阶逻辑对语义网络和框架进行形式化后的产物。描述逻辑一般支持一元谓词和二元谓词。一元谓词称为类，二元谓词称为关系。描述逻辑的重要特征是同时具有很强的表达能力和可判定性。</strong>描述逻辑是OWL的理论基础，下一篇文章再详细讨论</p><p><strong><em>To Be Continued ….</em></strong></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识图谱 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
