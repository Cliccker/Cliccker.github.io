<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>《算法设计与分析课程》笔记</title>
      <link href="/2020/07/19/xue-suan-fa/"/>
      <url>/2020/07/19/xue-suan-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="1-1-算法的基本概念"><a href="#1-1-算法的基本概念" class="headerlink" title="1.1__算法的基本概念"></a>1.1__算法的基本概念</h2><p>算法的重要属性——<code>正确</code>和<code>高效</code></p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200719143345.png" alt="事件复杂度" style="zoom:50%;" /><h2 id="1-2-算法举例"><a href="#1-2-算法举例" class="headerlink" title="1.2__算法举例"></a>1.2__算法举例</h2><h3 id="局部高点"><a href="#局部高点" class="headerlink" title="局部高点"></a>局部高点</h3><p>定义：存在列表$A$，若$A[i-1] \leq A[i] \geq A[i+1]$，则称$A[i]$为局部高点。不是所有序列都有局部高点，这里限制边界条件$A[-1] = A[n]= -\infty$。</p><h4 id="简单算法："><a href="#简单算法：" class="headerlink" title="简单算法："></a>简单算法：</h4><p>找出数列中任意一个局部高点</p><p>逐个索引，比较前后元素之间的大小</p><ul><li>最好的情况：第一个元素就是局部高点 <code>1次</code></li><li>最坏的情况：最后一个元素才是局部高点<code>n次</code></li></ul><p><font color="#4590a3" size="4px">算法分析应考虑最坏的情况</font>，实际分析中应尽量忽略数据的分布</p><p>所以简单算法的效率事$O(n)$，函数是一个单调递增的线性函数</p><h4 id="更高效的算法："><a href="#更高效的算法：" class="headerlink" title="更高效的算法："></a>更高效的算法：</h4><p>考虑每次查找都缩小查找的范围</p><p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200719151316.png" alt="三种可能存在的情况"></p><p>从中间的元素开始查找，可以在一次比较厚，缩小一半的搜索范围（二分法）</p><p>算法的效率为$O(log_2n)$</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何将MarkDown笔记导出至知乎</title>
      <link href="/2020/07/16/ru-he-jiang-markdown-dao-chu-zhi-zhi-hu/"/>
      <url>/2020/07/16/ru-he-jiang-markdown-dao-chu-zhi-zhi-hu/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 2019-11-26</span><span class="token keyword">import</span> re<span class="token keyword">import</span> sys<span class="token keyword">def</span> <span class="token function">replace</span><span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> output_file_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        pattern1 <span class="token operator">=</span> r<span class="token string">"\$\$\n*([\s\S]*?)\n*\$\$"</span>        new_pattern1 <span class="token operator">=</span> r<span class="token string">'\n&lt;img src="https://www.zhihu.com/equation?tex=\1" alt="\1" class="ee_img tr_noresize" eeimg="1">\n'</span>        pattern2 <span class="token operator">=</span> r<span class="token string">"\$\n*(.*?)\n*\$"</span>        new_pattern2 <span class="token operator">=</span>r<span class="token string">'\n&lt;img src="https://www.zhihu.com/equation?tex=\1" alt="\1" class="ee_img tr_noresize" eeimg="1">\n'</span>        f <span class="token operator">=</span> open<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>        f_output <span class="token operator">=</span> open<span class="token punctuation">(</span>output_file_name<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>        all_lines <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>        new_lines1 <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>pattern1<span class="token punctuation">,</span> new_pattern1<span class="token punctuation">,</span> all_lines<span class="token punctuation">)</span>        new_lines2 <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>pattern2<span class="token punctuation">,</span> new_pattern2<span class="token punctuation">,</span> new_lines1<span class="token punctuation">)</span>        f_output<span class="token punctuation">.</span>write<span class="token punctuation">(</span>new_lines2<span class="token punctuation">)</span>        f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>        f_output<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    file_name <span class="token operator">=</span> <span class="token string">'original_version.md'</span>    file_name_pre <span class="token operator">=</span> file_name<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    output_file_name <span class="token operator">=</span> <span class="token string">"zhihu_version.md"</span>    replace<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> output_file_name<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Trans from {} to {}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> output_file_name<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>放在同一文件夹下，将markdown文件改名为’original_version.md’，运行就可以了</p>]]></content>
      
      
      <categories>
          
          <category> 技巧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MarkDown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读论文——On2Vec：基于嵌入的本体群体关系预测</title>
      <link href="/2020/07/16/2020-7-16-du-lun-wen-on2vec-ji-yu-qian-ru-de-ben-ti-qun-ti-guan-xi-yu-ce/"/>
      <url>/2020/07/16/2020-7-16-du-lun-wen-on2vec-ji-yu-qian-ru-de-ben-ti-qun-ti-guan-xi-yu-ce/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1 id="读论文——On2Vec：基于嵌入的本体群体关系预测"><a href="#读论文——On2Vec：基于嵌入的本体群体关系预测" class="headerlink" title="读论文——On2Vec：基于嵌入的本体群体关系预测"></a>读论文——On2Vec：基于嵌入的本体群体关系预测</h1><p><em>原标题*：On2Vec: Embedding-based Relation Prediction for Ontology Population  *<a href="https://arxiv.org/abs/1809.02382" target="_blank" rel="noopener">来源</a></em> <a href="https://github.com/muhaochen/on2vec" target="_blank" rel="noopener"><em>代码</em></a></p><h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>Ontology population(本体填充)，指将原始信息（可以是非结构化、半结构化或者结构化的数据）转换为本体实例的过程。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>现有的研究已经能将基于翻译的知识嵌入模式应用到实例层级的图谱中，实现较好的填充效果。相比于实例图谱，本体视图中的关系事实包含了更多复杂的语义关系，包括<code>可传递性</code>，<code>对称性</code>和<code>层次关系</code>。这种关系对于现有的嵌入模式来说过于复杂，且直接应用不可行。在TransE中我们用能量方程$S_{r}(\mathbf{s}, \mathbf{t})$去衡量一个三元组的可信度，函数值越小，代表描述就越准确。<br>$$<br>S_{r}(\mathbf{s}, \mathbf{t})=|\mathbf{s}+\mathbf{r}-\mathbf{t}|<br>$$<br>文章提出这种能量方程会导致如图所示的问题：</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/批注 2020-07-16 162227.png" alt="图1" title="图1" style="zoom:50%;" /><ul><li><p>Case1：$\boldsymbol {A,B,C}$是三个概念$A,B,C$的嵌入，假设<br>$$<br>\boldsymbol {A+r\approx B，B+r\approx C}<br>$$<br>即$r$是一种具有传递性的关系，按照传递性的原则应当有：<br>$$<br>\boldsymbol {A+r\approx C}<br>$$<br>然而事实上：<br>$$<br>\boldsymbol {A + r\ne C}<br>$$<br>这个结论很容易就能从图中观察出来。</p></li><li><p>Case2：$\boldsymbol {E,F}$是两个概念$E,F$的嵌入，假设：<br>$$<br>\boldsymbol {E+r\approx F}<br>$$<br>且$r$为对称性关系，则应有：</p><p>$$<br>\boldsymbol {F+r\approx E}<br>$$</p><p>然而事实上：<br>$$<br>\boldsymbol {F+r\ne E}<br>$$<br>这是因为向量$\boldsymbol r \ne 0$。</p></li></ul><h3 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h3><p>由两个模型组件组成的On2vec，包括：</p><ol><li>Component-specific Model （组件特定模型）将概念和关系编码嵌入低维空间，且不丢失相关属性；</li><li>Hierarchy Model  （层次模型）集中处理层级关系。</li></ol><h2 id="技术路线"><a href="#技术路线" class="headerlink" title="技术路线"></a>技术路线</h2><h3 id="符号及其含义"><a href="#符号及其含义" class="headerlink" title="符号及其含义"></a>符号及其含义</h3><table><thead><tr><th align="center">字符</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">$G(C,R）$</td><td align="center">一个图谱</td></tr><tr><td align="center">$C$</td><td align="center">一系列的概念</td></tr><tr><td align="center">$R$</td><td align="center">一系列语义关系</td></tr><tr><td align="center">$T=(s,r,t)$</td><td align="center">一个三元组</td></tr><tr><td align="center">$\boldsymbol s$</td><td align="center">vectors of source</td></tr><tr><td align="center">$\boldsymbol r$</td><td align="center">vectors of relation</td></tr><tr><td align="center">$\boldsymbol t$</td><td align="center">vectors of target</td></tr><tr><td align="center">$R_{tr}$</td><td align="center">传递关系</td></tr><tr><td align="center">$R_s$</td><td align="center">对称关系</td></tr><tr><td align="center">$R_h$</td><td align="center">层级关系</td></tr><tr><td align="center">$R_r$</td><td align="center">将粗概念划分为细概念的细化关系</td></tr><tr><td align="center">$R_c$</td><td align="center">将细概念划分到粗概念的强制关系</td></tr><tr><td align="center">$R_o$</td><td align="center">其他关系</td></tr></tbody></table><p>我可以用不同的数学表达式展示各种关系，如传递关系$R_{tr}$</p><p>$$<br>given: r \in R_{tr} \ c_1,c_2,c_3 \in G \ if:(c_1,r,c_2),(c_2,r,c_3) \in G<br>\ then : (c_1,r,c_3) \in G<br>$$</p><h3 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h3><h4 id="Component-specific-Model"><a href="#Component-specific-Model" class="headerlink" title="Component-specific Model"></a>Component-specific Model</h4><h5 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h5><p>这个名字不知道怎么翻译合适。暂时称为<code>特定组件模型</code>。</p><p>文章在这里认为，<code>投影函数</code>$f_r$在投影时，就已经把这些关系中的概念放在了有冲突的位置上，原因我在上面已经解释过了。为了解决这个两个问题，CSM提出了用两个不相同的$f_r$，去区别同一概念在不同三元组中的嵌入。仔细解释一下就是，对于同一个概念，在不同三元组中的<code>组分</code>会不同，因此在衡量一个三元组的<code>可信度</code>时，需要对该三元组中概念的<code>嵌入</code>做一定的调整才能解决这些冲突。据此文章提出了一种新的衡量可信度方程$S_{d}(T)$</p><p>$$<br>S_{d}(T)=| f_{1, r}(\mathbf{s})+\mathbf{r}-f_{2, r}(\mathbf{t}) \mid<br>$$</p><p>式中的$f_{1,r}(x),f_{2,r}(x)$是作用于头尾概念的不同投影函数，后文提到了这两个函数实际就是两个$k \times k $的矩阵，对于不同的关系，选用不同的矩阵。$S_{d}$在消除冲突的同时，还能用来实现挖掘本体中隐藏的关系。现在我们在处理Case 1时，就能把在不同三元组中的$B$放在不同的位置。对于Case 2 ，可以让$E，F$互换位置。</p><h5 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h5><p>和别的模型选择<code>实体</code>做负面样本不一样的是，CSM选择<code>关系</code>来做负面的样本，提出来的loss长这样：</p><p>$$<br>\begin{aligned}<br>S_{\mathrm{CSM}}(G)=&amp; \sum_{(s, r, t) \in G}\left[\left|f_{1, r}(\mathbf{s})+\mathbf{r}-f_{2, r}(\mathbf{t})\right|\right.\left.-\left|f_{1, r}(\mathbf{s})+\mathbf{r}^{\prime}-f_{2, r}(\mathbf{t})\right|+\gamma_{1}\right]_{+}<br>\end{aligned}<br>$$</p><p>式中的$r’$是一个<code>并不能连接</code>$s$和$t$的<code>随机选取</code>的关系，$\gamma_{1}$是一个正矩阵。学习目的是为了得到更准确的$f_{1,r}(x),f_{2,r}(x)$</p><h4 id="Hierarchy-Model"><a href="#Hierarchy-Model" class="headerlink" title="Hierarchy Model"></a>Hierarchy Model</h4><h5 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h5><p>对于层次关系，这篇文章提到了我读的<a href="https://zhuanlan.zhihu.com/p/156791237" target="_blank" rel="noopener">另一篇论文</a>中对层级关系的处理方法，就是让他们在向量空间上尽量聚集。如图</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200717125248.png" title ="图2 上一篇文章提到的分组技术" style="zoom: 67%;" /><p>文章提出较为精细的概念，比如”person”，可以参与多个关系事实，这就导致了在嵌入时一个关系事实容易受到其他关系事实的影响，降低了三元组的可信度。HM要做的是将每一个精细概念的嵌入更加紧密的<code>融合</code>在一起。为了做到这一点，文章提出了一种<code>精炼</code>的操作，如图：</p><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200717151516.png" alt="图3 ‘精炼’操作" style="zoom:67%;" /><p>看起来很复杂，其实就是让所有<code>直接</code>相关的细粒度概念聚集到粗粒度概念周围，形成一个集合，减少了关系事实之间的干扰。举个例子，我可以从$(c_1,isA,c_2),(c_2,isA,c_3)$得到$(c_1,isA,c_3)$，但是这里认为$c_1$并不与$c_3$直接相关，故$c_1 \notin\sigma(c_3,isA)$。形象一点说，本来我们有很多亲戚，现在我们亲戚都不认了，只认兄弟姐妹父亲母亲，瞬间催婚催生的嘴就少了很多张！</p><p>据此列出能量方程：<br>$$<br>\begin{aligned}<br>S_{h m}(G) &amp;=\sum_{r \in R_{r}} \sum_{s \in C} \sum_{t \in \sigma(s, r)} \omega\left(f_{1, r}(\mathbf{s})+\mathbf{r}, f_{2, r}(\mathbf{t})\right) \<br>&amp;+\sum_{r \in R_{c}} \sum_{t \in C} \sum_{s \in \sigma(t, r)} \omega\left(f_{2, r}(\mathbf{t})-\mathbf{r}, f_{1, r}(\mathbf{s})\right)<br>\end{aligned}<br>$$<br>$f_{1,r}和f_{2,r}$就是上一节写到的调整函数。$\omega (x)$是用来计算两个向量的相似度的单调递增的函数，算法中直接计算两个向量的余弦距离，余弦距离越小，余弦相似度越高。第一行计算的是所有<code>直接细化关系</code>的三元组的可信度，第二行计算的是所有<code>直接强制关系</code>的三元组的可信度，两个可信度相加得到整个图谱的可信度。</p><h5 id="优化-1"><a href="#优化-1" class="headerlink" title="优化"></a>优化</h5><p>$$<br>\begin{aligned}<br>S_{\mathrm{HM}}(G) &amp;=\sum_{r \in R_{r}} \sum_{s \in C} \sum_{t \in \sigma(s, r) \wedge t^{\prime} \notin \sigma(s, r)} S_{h r} \<br>&amp;+\sum_{r \in R_{c}} \sum_{t \in C} \sum_{s \in \sigma(t, r) \wedge s^{\prime} \notin \sigma(t, r)} S_{h c}<br>\end{aligned}<br>$$</p><p>$s’$和$t’$在这里做负面样本，其中</p><p>$$<br>S_{h r}=\left[\omega\left(f_{1, r}(\mathbf{s})+\mathbf{r}, f_{2, r}(\mathbf{t})\right)-\omega\left(f_{1, r}(\mathbf{s})+\mathbf{r}, f_{2, r}\left(\mathbf{t}^{\prime}\right)\right)+\gamma_{2}\right]_{+}<br>$$</p><p>$$<br>S_{h c}=\left[\omega\left(f_{2, r}(\mathbf{t})-\mathbf{r}, f_{1, r}(\mathbf{s})\right)-\omega\left(f_{2, r}(\mathbf{t})-\mathbf{r}, f_{1, r}\left(\mathbf{s}^{\prime}\right)\right)+\gamma_{2}\right]_{+}<br>$$</p><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200717171122.png" alt="图4 算法" style="zoom:67%;" /><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/img/20200717172910.png" alt="图5 数据集" style="zoom:67%;" /><p>在实验中，这个模型被用来做<code>关系预测</code>和<code>关系识别</code></p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>这篇论文看的我蛮痛苦的，因为里面好多用词都不是那么精准，而且也没有合适的图例表达算法逻辑，和之前发出来那篇差了好多，许多地方并不能说服我，有时间再看看他的源码吧。果然好论文一定是容易读的论文！</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 本体 </tag>
            
            <tag> 知识嵌入 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>烧卖有梗</title>
      <link href="/2020/07/14/146/"/>
      <url>/2020/07/14/146/</url>
      
        <content type="html"><![CDATA[<p>从今年开始，学生们最恐怖的噩梦从梦到上学没穿裤子变成了网课没关麦。</p>]]></content>
      
      
      <categories>
          
          <category> 想法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 一个小笑话 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《知识图谱：方法、实践与应用》阅读笔记——知识图谱表示与建模（2）</title>
      <link href="/2020/07/14/zhi-shi-tu-pu-fang-fa-shi-jian-yu-ying-yong-yue-du-bi-ji-zhi-3/"/>
      <url>/2020/07/14/zhi-shi-tu-pu-fang-fa-shi-jian-yu-ying-yong-yue-du-bi-ji-zhi-3/</url>
      
        <content type="html"><![CDATA[<p>距离上一篇读书笔记已经有一段日子了，中间打了很多代码，也摸了很多🐟。有时候还是比较细化打代码的，感觉比码字有意思。但是有意思的事做太多就不会有积累了，所以接着填这个坑叭！</p><h2 id="互联网时代的语义网知识表示框架"><a href="#互联网时代的语义网知识表示框架" class="headerlink" title="互联网时代的语义网知识表示框架"></a>互联网时代的语义网知识表示框架</h2><p>上一篇文章中提到的“语义网”让知识表示迎来了新的春天，不过也出现了新的挑战——标准语言在哪里？HTML和XML已经跟不上这个时代了（时代变了，大人）。W3C提出了新的标准语言RDF和OWL，我们一起来欣赏一下吧。</p><h3 id="核心成员RDF"><a href="#核心成员RDF" class="headerlink" title="核心成员RDF"></a>核心成员RDF</h3><p>RDF中的知识永远是以三元组的形式呈现出来，就是(subject,predicate,object)， 亦即（主语，谓语，宾语）。我们可以把它看成一个传统意义上的句子结构中的主谓宾，比如“我喜欢吃冰淇淋，吃完就长肉”👉（我，喜欢，吃冰淇淋）（我，长，肉）。同时我们也可以用（我，在什么时候吃雪糕，“12点”^xsd:date）表示“我在12点吃了雪糕”。从中我们可以看出，RDF中的主语一定是一个个体（individual），书中也解释了个体是类的实例，比如我是人“类”的一个实例，谓语表示属性，宾语可以是个体也可是实例。</p><p>我们拿我怎么变胖来构建来建立一个图谱，如下</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-153445.png" alt=""></p><p>我变胖的一个图谱</p><p>再来把他写成英文，如下</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-153804-1.png" alt=""></p><p>a KG of my growing weights</p><p>由于在RDF中的主谓宾都有一个全局标识，所以我们再给这个图谱中的元素加点料</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-155352-1.png" alt=""></p><p>看起来是不是更像回事了？</p><p>全局URL可以简化为前缀URL，当然也可以出现没有前缀的空白节点（BlankNode），长这样</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-160905.png" alt=""></p><p>空白节点可以代入你我他哦</p><h3 id="开放世界假设"><a href="#开放世界假设" class="headerlink" title="开放世界假设"></a>开放世界假设</h3><p>这个假设听起来是不是很酷呢？实际上他比听起来更酷。开放世界假设使得RDF图谱里的知识可以是不完整的，例如我喜欢吃冰激凌，并不意味着我只喜欢吃冰激凌，雪糕当然也是不错的选择😋，(i,enjoy,ice-cream)代表冰淇淋至少是我的一个爱好！采用开放世界假设有什么好处呢？答案是可以实现分布式存储，像这样：</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-162100.png" alt=""></p><p>我喜欢冰淇淋&amp;冰淇淋是光明牌的</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-162503.png" alt=""></p><p>我喜欢吃光明的冰淇淋</p><h3 id="RDF-Schema——RDFS"><a href="#RDF-Schema——RDFS" class="headerlink" title="RDF Schema——RDFS"></a>RDF Schema——RDFS</h3><p>RDFSchema（RDF模式，简称RDFS）提供了对类和属性的简单描述，包括上下级关系（subclass_of)，定义域(domian)，值域（range）等。这一步我直接上书上的图：</p><p><img src="http://121.199.51.214/wp-content/uploads/2020/07/%E6%89%B9%E6%B3%A8-2020-07-14-163732.png" alt=""></p><p>可谓图糙理不糙，上面是本体视图，下面是实例视图</p><hr><h2 id="主力成员OWL🦉"><a href="#主力成员OWL🦉" class="headerlink" title="主力成员OWL🦉"></a>主力成员OWL🦉</h2><p>RDF(S)可以表示一些简单的语义，但是如果场景更加复杂的化，RDF就不太行了。RDF本身缺少很多常用的特征，把书中写出来的几个简单罗列：</p><p>1.无法准确的描述属性的定义、特征；</p><p>2.无法描述类、个体属性是否等价（是我杀了我？）</p><p>3.基数约束，即一个人不可能有两个爸爸（出了于谦儿子郭小宝）</p><p>总之，RDF在描述事实的时候就像是一个年幼的孩子👶，很多事情很多关系他还不懂，我们需要一个更成熟的本体语言来替我们表达知识！</p><h3 id="OWL语言特征"><a href="#OWL语言特征" class="headerlink" title="OWL语言特征"></a>OWL语言特征</h3><p>OWL1.0有三个子语言，OWL Lite&lt;OWL DL&lt;OWL Full。书中写道这三者选择的原则</p><blockquote><p>●选择OWL Lite还是OWL DL主要取决于用户需要整个语言在多大程度上给出约束的可表达性；</p><p>●选择OWL DL还是OWL Full主要取决于用户在多大程度上需要RDF的元模型机制，如定义类型的类型以及为类型赋予属性；</p><p>●当使用OWL Full而不是OWL DL时，推理的支持可能不能工作，因为目前还没有完全支持OWL Full的系统实现。</p></blockquote><p>OWL不是完全独立于RDF的，他们在很多地方都有相似之处，不过我觉得知道这个没用！</p><h3 id="OWL重要词汇"><a href="#OWL重要词汇" class="headerlink" title="OWL重要词汇"></a>OWL重要词汇</h3><ol><li>等价性声明</li><li>属性传递声明👉a大于b，b大于c 可以推出 a大于c</li><li>属性互逆声明 👉a大于b，b小于a 大于小于这两个属性互逆</li><li>属性的函数声明👉a的大写是A</li><li>属性的对称性声明👉a=b，b=a</li><li>属性的全称限定声明👉如：母亲一定是女人</li><li>属性的存在限定声明👉如：我一部分的文章发在知乎上</li><li>属性的基数限定声明👉如：我只能有“一个”父亲</li><li>相交的类声明👉如：妈妈是有孩子的人，即有孩子和人的交集</li></ol><p>这些词汇在书上写的很详细，这个笔记抄下来就没意思了。</p><h3 id="OWL版本"><a href="#OWL版本" class="headerlink" title="OWL版本"></a>OWL版本</h3><p>OWL2的三大子语言是OWL 2 RL、OWL 2 QL和OWL 2 EL，关于这三种语言的词汇，书中有写错的地方，需要去别处找更准确的总结。</p><hr><h2 id="语义Markup表示语言"><a href="#语义Markup表示语言" class="headerlink" title="语义Markup表示语言"></a>语义Markup表示语言</h2><p>语义网进一步定义了在网页中嵌入语义Markup的方法和表示语言。被谷歌知识图谱以及Schema.Org采用的语义Markup语言主要包括JSON-LD、RDFa和HTML5 MicroData。</p><p><strong>我似乎感觉到这本书不怎么样了，因为书里一直在罗列概念也没说要自己动手做。还是只看自己感兴趣的内容吧</strong></p><p><strong><em>To Be Continued</em></strong></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识图谱 </tag>
            
            <tag> owl </tag>
            
            <tag> rdf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《知识图谱：方法、实践与应用》阅读笔记——知识图谱概述</title>
      <link href="/2020/07/13/zhi-shi-tu-pu-fang-fa-shi-jian-yu-ying-yong-yue-du-bi-ji-zhi-2/"/>
      <url>/2020/07/13/zhi-shi-tu-pu-fang-fa-shi-jian-yu-ying-yong-yue-du-bi-ji-zhi-2/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是知识图谱？"><a href="#什么是知识图谱？" class="headerlink" title="什么是知识图谱？"></a>什么是知识图谱？</h2><p>一种用<strong>图模型</strong>(probabilistic graphic models)来描述知识和建模世界万物之间的关联关系的技术方法。由<strong>节点</strong>和<strong>边</strong>组成</p><h2 id="知识图谱的价值"><a href="#知识图谱的价值" class="headerlink" title="知识图谱的价值"></a>知识图谱的价值</h2><ol><li>辅助搜索</li><li>辅助问答</li><li>辅助大数据分析</li><li>辅助语言理解，人机之间的相互理解</li></ol><p><img src="https://pic4.zhimg.com/v2-c83e96721a4635920b7aac623783042f_b.png" alt=""></p><p>这道看似简单的题，机器却毫无办法。“到底谁大谁小？”</p><p>5.辅助设备互联，机器与机器之间的相互理解书中一直强调的辅助作用，是不是意味着知识图谱更像一种锦上添花的工具？</p><h2 id="一些知识图谱项目"><a href="#一些知识图谱项目" class="headerlink" title="一些知识图谱项目"></a>一些知识图谱项目</h2><p>freebase​</p><p>wikidata（需要梯子）</p><p><img src="https://pic4.zhimg.com/v2-8ef39dbe4682280e4814220dfcbc49d3_b.png" alt=""></p><p>如何构建一个规模化的知识图谱</p><p>值得注意的是阿里巴巴有自己的电商知识图谱，规模达到了百亿级别。</p><h2 id="知识图谱的技术流程"><a href="#知识图谱的技术流程" class="headerlink" title="知识图谱的技术流程"></a>知识图谱的技术流程</h2><ul><li>知识图谱采用更加规范而标准的概念模型、本题术语和语法格式来建模和描述数据</li><li>通过语义链接来增强数据之间的关系</li></ul><p>_就像是一张网。_知识图谱方法论涉及知识表示、知识获取、知识处理和知识利用多个方面。一般流程为：</p><ol><li>首先确定知识表示模型，然后根据数据来源选择不同的知识获取手段导入知识</li><li>接着综合利用知识推理、知识融合、知识挖掘等技术对构建的知识图谱进行质量提升，</li><li>最后根据场景需求设计不同的知知识访问与呈现方法，如语义搜索、问答交互、图谱可视化分析等。</li></ol><h3 id="1-知识来源"><a href="#1-知识来源" class="headerlink" title="1.知识来源"></a>1.知识来源</h3><p>有多种来源来获取知识，除了文本，我们还可以考虑结构化数据库、多媒体数据、传感器数据和人工众包。对于文本数据源，我们要用到<strong>自然语言处理技术。</strong>对于各种结构化数据库，<strong>需要将结构化数据定义到本体模型之间的语义映射，再通过编写语义翻译工具实现转化。</strong></p><h3 id="2-知识表示"><a href="#2-知识表示" class="headerlink" title="2.知识表示"></a><strong>2.知识表示</strong></h3><p>即用计算机符号来表述人类的语言</p><p><img src="https://pic2.zhimg.com/v2-9ef1ddd2692744e97469778a17e53765_b.png" alt=""></p><p>知识表示的产出目标</p><p><img src="https://pic1.zhimg.com/v2-c3c4263647d7b65e840280206d4be42c_b.png" alt=""></p><p>知识图谱分类</p><h3 id="3-知识抽取"><a href="#3-知识抽取" class="headerlink" title="3.知识抽取"></a>3.知识抽取</h3><p>知识抽取按任务划分可以分为概念抽取、实体识别、关系抽取、事件抽取和规则抽取等</p><p><img src="https://pic2.zhimg.com/v2-46f64c05ef7f4c2de99f6324ca7bda29_b.png" alt=""></p><p>知识抽取的划分</p><p>书中解释了远程监督的思想远程监督的思想是，利用一个大型的语义数据库自动获取关系类型标签。这些标签可能是含有噪声的，但是大量的训练数据在一定程度上可以抵消这些噪声。另外，一些工作通过多任务学习等方法将实体和关系做联合抽取。最新的一些研究则利用强化学习减少人工标注并自动降低噪声。如何减少人工标注，是我现阶段工作的重点。</p><h3 id="4-知识融合"><a href="#4-知识融合" class="headerlink" title="4.知识融合"></a>4.知识融合</h3><p>外部数据库合并到本体知识库时，需要解决两个问题</p><ol><li>通过模式层(?)的融合，将新的本体融入已有的本体库中，以及新旧本体的融合</li><li>数据层的融合，包括实体的指称、属性、关系和所属类别。</li></ol><p><strong>关键问题是如何避免实例以及关系的冲突问题，造成不必要的冗余</strong></p><p><em>文中提到的本体概念，这边没有太理解，需要另找专门的文献再熟悉熟悉</em></p><h3 id="5-知识图谱的补全和推理（重头戏"><a href="#5-知识图谱的补全和推理（重头戏" class="headerlink" title="5.知识图谱的补全和推理（重头戏)"></a>5.知识图谱的补全和推理（重头戏)</h3><h3 id="6-知识检索和知识分析"><a href="#6-知识检索和知识分析" class="headerlink" title="6.知识检索和知识分析"></a>6.知识检索和知识分析</h3><p>包括语义检索和智能问答</p><h2 id="知识图谱相关技术"><a href="#知识图谱相关技术" class="headerlink" title="知识图谱相关技术"></a>知识图谱相关技术</h2><p><img src="https://pic4.zhimg.com/v2-7793c97d516a7921e3efbda54397813f_b.png" alt=""></p><p>数据库与数据模型</p><p><img src="https://pic4.zhimg.com/v2-258314714963e49e9bb038c5ade3ce93_b.png" alt=""></p><p>知识问答</p><p><img src="https://pic2.zhimg.com/v2-a47b6ecd00ed64de048f2419e3aebbd1_b.png" alt=""></p><p>知识推理</p><p>基于表示学习的知识图谱推理研究的主要研究趋势是，一方面提高表示学习结果对知识图谱中含有的语义信息的捕捉能力，目前的研究多集中在链接预测任务上，其他推理任务有待跟进研究；另一方面是利用分布式表示作为桥梁，将知识图谱与文本、图像等异质信息结合，实现信息互补以及更多样化的综合推理。如果说我们人的思维是一个已经存在的知识图谱，那么我们在学习知识的时候，基于知识表示的学习方法一定是更快的，相比于基于规则的推理而言，知识来源的渠道更广泛，更丰富，更能激发“兴趣”。后面还写到了推荐系统与去中心化，这里暂且不论。</p><p><strong><em>第一章 完</em></strong></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识图谱 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《知识图谱：方法、实践与应用》阅读笔记——知识图谱表示与建模（1）</title>
      <link href="/2020/07/13/zhi-shi-tu-pu-fang-fa-shi-jian-yu-ying-yong-yue-du-bi-ji-zhi/"/>
      <url>/2020/07/13/zhi-shi-tu-pu-fang-fa-shi-jian-yu-ying-yong-yue-du-bi-ji-zhi/</url>
      
        <content type="html"><![CDATA[<p>上一篇文章中我们介绍了什么是知识图谱，而这一篇讲述了知识图谱的表示和建模方法。和编程之前需要选择平台一样，知识图谱的建模也需要我们来选择一种方法。本章主要讲述了如何使用这些方法对知识进行建模。</p><h2 id="1-什么是知识表示"><a href="#1-什么是知识表示" class="headerlink" title="1.什么是知识表示"></a>1.什么是知识表示</h2><p>知识表示的五大用途和特点<strong>客观事物的机器标示</strong>（A KR is a Surrogate），即知识表示首先需要定义客观实体的机器指代或指称。 <strong>一组本体约定和概念模型</strong>（A KR is a Set of Ontological Commitments），即知识表示还需要定义用于描述客观事物的概念和类别体系。 <strong>支持推理的表示基础</strong>（A KR is a Theory of Intelligent Reasoning），即知识表示还需要提供机器推理的模型与方法。 <strong>用于高效计算的数据结构</strong>（A KR is a medium for Efficient Computation），即知识表示也是一种用于高效计算的数据结构。 <strong>人可理解的机器语言</strong>（A KR is a Medium of Human Expression），即知识表示还必须接近于人的认知，是人可理解的机器语言。再来梳理一下知识表示发展的脉络</p><p><img src="https://pic2.zhimg.com/v2-a1c0be286efd3f1dcd5c86f8a1b6287d_b.png" alt="" title="知识表示发展脉络"></p><p>知识表示发展脉络</p><p>Q：为什么要引入向量的概念？A: 简单来讲，向量能够表示更多字符无法表示的隐藏的知识，且更易于推理。</p><hr><h3 id="2-早期的一些表示方法"><a href="#2-早期的一些表示方法" class="headerlink" title="2.早期的一些表示方法"></a>2.早期的一些表示方法</h3><ul><li><strong>一阶谓词逻辑</strong></li></ul><p><strong><em>第一步：列出一些基本逻辑</em></strong></p><p>COMPUTER（x）：x是计算机系的学生。LIKE（x，y）：x喜欢y。HIGHER（x，y）：x比y长得高。</p><p><strong><em>第二步：将个体代入谓词中</em></strong></p><p>这里涉及的个体有：张晓辉（zhangxh），编程序（programming），李晓鹏（lixp），以函数father（lixp）表示李晓鹏的父亲。</p><p><img src="https://www.zhihu.com/equation?tex=COMPUTER(zhangxh)%20%2C~LIKE(zhangxh%2C%20programming)%20%20%2CHIGHER(lip%2C%20father%EF%BC%88lixp%EF%BC%89)" alt="COMPUTER(zhangxh) ,~LIKE(zhangxh, programming)  ,HIGHER(lip, father（lixp）)">)COMPUTER(zhangxh) ,~LIKE(zhangxh, programming) ,HIGHER(lip, father（lixp）)</p><p><strong><em>第三步：根据语义，用逻辑联接词将它们联接起来，就得到了表示上述知识的谓词公式</em></strong><img src="https://www.zhihu.com/equation?tex=COMPUTER(zhangxh)%20%E2%88%A7LIKE(zhangxh%2C%20programming)" alt="COMPUTER(zhangxh) ∧LIKE(zhangxh, programming)"></p><p>COMPUTER(zhangxh) ∧LIKE(zhangxh, programming)</p><p><em>张晓辉是一个计算机系的学生，他喜欢编程</em></p><p>HIGHER(lixp, father( lixp))</p><p><em>李晓鹏比他父亲长得高</em></p><ul><li><strong>霍恩子句和霍恩逻辑</strong></li></ul><p><strong>霍恩子句（Horn Clause）得名于逻辑学家Alfred Horn[6]。一个子句是文字的析取。霍恩子句是带有最多一个肯定（positive）文字的子句，肯定文字指的是没有否定符号的文字。例如，Øp1∨…∨Øpn∨ q是一个霍恩子句，它可以被等价地写为（p1∧…∧pn）→ q。Alfred Horn于1951年撰文指出这种子句的重要性。</strong>这一段书里讲的内容属实没看明白，但是也不是特别重要，因为在知识表示方面他已经是过去式了！</p><ul><li><strong>语义网络</strong></li></ul><p>语义网络在形式上式一个带有标识的有向图，由节点和连接弧组成。如图</p><p><img src="https://pic1.zhimg.com/v2-b1be71183c8a9d116fc9fe7e66d25528_b.png" alt=""></p><p>语义网络的构成</p><p>语义网络的<strong>缺点</strong>是</p><ol><li>同一段知识可能有多种多样的表示形式。不同的表示形式会提高处理不同语义网络的复杂性。</li><li>如果你想要理解一个语义网络的含义，那你只能依靠其处理程序。即语义网络缺少一套公认的形式表示体系。这会产生什么样的影响呢？举个栗子，假如全世界各个国家的人只说自己本国的语言，那跨国交流就只能依靠打手势了，使得知识表示非常容易产生偏差。</li></ol><p><strong><em>“我对着她竖起了中指，她却以为我爱上了她”</em></strong></p><ul><li><strong>框架</strong></li></ul><p><strong>其理论的基本思想是：认为人们对现实世界中各种事物的认识都以一种类似于框架的结构存储在记忆中。</strong></p><p><img src="https://pic3.zhimg.com/v2-71697617962190b91b396e34f73f9ef6_b.png" alt=""></p><p>一个框架的实例</p><p>我们可以看到框架中有很多默认值，这种默认值会大大增加推理的难度。</p><ul><li><strong>描述逻辑</strong></li></ul><p><strong>描述逻辑可以被看成是利用一阶逻辑对语义网络和框架进行形式化后的产物。描述逻辑一般支持一元谓词和二元谓词。一元谓词称为类，二元谓词称为关系。描述逻辑的重要特征是同时具有很强的表达能力和可判定性。</strong>描述逻辑是OWL的理论基础，下一篇文章再详细讨论</p><p><strong><em>To Be Continued ….</em></strong></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 知识图谱 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
